{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGo/PKL4d5lX+99atrOwt4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ms624atyale/CL4Research/blob/main/2_2_Speech2Text_WordCount_WordErrorRate_Original_Compressed_ExtractExcel_Subj1_ParkYeIn_2ndRecording.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this modified code, the convert_speech_to_text() function remains the same as before, which converts speech to text using Google STT. The count_words() function also remains the same, which counts the number of words in the text.\n",
        "\n",
        "The code iterates over the WAV files in the specified folder. For each WAV file, it converts the speech to text using convert_speech_to_text(), then counts the number of words in the converted text using count_words(). Finally, it prints the filename, converted text, and word count for each WAV file.\n",
        "\n",
        "Make sure to adjust the folder_path variable to the actual path of your WAV files. After making these adjustments, run the code, and it will apply Google STT on each WAV file, retrieve the converted text, and count the number of words in the text for each WAV file."
      ],
      "metadata": {
        "id": "qQVtTYE72IgK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üêπ <font color = 'brown'> google STT (SpeechRecognition package) applied to a list of oritinal wav. files and their corresponding word count** ‚§µÔ∏è\n",
        "\n",
        "###**üåµ 1. STT (subj1, rep1, all text, original)**"
      ],
      "metadata": {
        "id": "fXvHSq8o74HD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "import speech_recognition as sr\n",
        "import os\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "    lowercase_text = text.lower()  # Convert the text to lowercase\n",
        "\n",
        "    return lowercase_text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"/content/sample_data/subj1_para_8original\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")"
      ],
      "metadata": {
        "id": "teUoaGzw2s7V",
        "outputId": "61153a86-25fe-4c70-e13f-746c4c256635",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "File: subj1_session1_rep3.wav\n",
            "Text: the nurse win and the song world is putting which was stronger when a traveler came around worked in the alarm clock they are really that the one who first succeed in making the traveler take his clothes off should be considered stronger than the other then the nurse wind blew as hard as he could but\n",
            "Word Count: 57\n",
            "\n",
            "File: subj1_session1_rep1.wav\n",
            "Text: the nurse wind and the sun world is building which was the stronger when a traveler came along work in a warm clock they are reset the one who first succeeded in making the traveler take his clock of should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely the traveler from his club around him and i lost the nursery and immediately go traveling was only\n",
            "Word Count: 82\n",
            "\n",
            "File: subj1_session1_rep5.wav\n",
            "Text: the nurse win and the song where they speak english with the stronger when the traveler came or not in the room clock they agreed that the one who first succeed in making the traveler take his clock off should be considered stronger than the other than the north wind blew as hard as he could put the more he blew the more closely did the turbo for his club around him and i left the list the nursery was over to confess that the song was the stronger of the two\n",
            "Word Count: 92\n",
            "\n",
            "File: subj1_session1_rep2.wav\n",
            "Text: the nursery and the sun world is putting which was stronger when i travel i came along work in a warm club they are really that the one who forced to succeed in making the traveler take his clock of should be considered stronger than the other in the nurse main blue as hard as he could put them away he blew the more closely did the traveler for his club around him and i lost the nursery nursery\n",
            "Word Count: 79\n",
            "\n",
            "File: subj1_session1_rep6.wav\n",
            "Text: the nurse mean and the song world is putting which was the stronger when a traveler came along rough in a warm clock they agreed that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could the more he blew the more closely together for his clock around him and i left the nursery was obviously to confess that the song was the stronger of the two\n",
            "Word Count: 87\n",
            "\n",
            "File: subj1_session1_rep4.wav\n",
            "Text: the nurse wind and the sun world is putting this was the stronger when a traveler came along with the warm clock they are read that the one who first succeeded in making the traveler take his clock off should be considered a stronger than the other than the north wind blow us hard as he could put the more he blew the more closely did the traveler for his clock around him and unless the north wind gave up the tent in the song in the sky shine on me and immediately was alive to confess that the sun was the stronger of\n",
            "Word Count: 104\n",
            "\n",
            "File: subj1_session1_rep7.wav\n",
            "Text: the nurse win and the sun was disputing which was the stronger when a traveler came along route in the warm clothes they are great that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely the doctor for his clock around him and i left and there's one game of the attempt in the sun in the sky shine at warmly and immediately to travel to the nurse when was over to confess that the sun was the stronger of the two\n",
            "Word Count: 111\n",
            "\n",
            "File: subj1_session1_rep8.wav\n",
            "Text: the nurse win and the sun was disputing which was the stronger when a traveler came along route in the warm clothes they are great that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely the doctor for his clock around him and i left and there's one game of the attempt in the sun in the sky shine at warmly and immediately to travel to the nurse when was over to confess that the sun was the stronger of the two\n",
            "Word Count: 111\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hypothesis_texts = [\"the nurse wind and the sun world is building which was the stronger when a traveler came along work in a warm clock they are reset the one who first succeeded in making the traveler take his clock of should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely the traveler from his club around him and i lost the nursery and immediately go traveling was only\",\n",
        "                    \"the nursery and the sun world is putting which was stronger when i travel i came along work in a warm club they are really that the one who forced to succeed in making the traveler take his clock of should be considered stronger than the other in the nurse main blue as hard as he could put them away he blew the more closely did the traveler for his club around him and i lost the nursery nursery\",\n",
        "                    \"the nurse win and the song world is putting which was stronger when a traveler came around worked in the alarm clock they are really that the one who first succeed in making the traveler take his clothes off should be considered stronger than the other then the nurse wind blew as hard as he could but\",\n",
        "                    \"the nurse wind and the sun world is putting this was the stronger when a traveler came along with the warm clock they are read that the one who first succeeded in making the traveler take his clock off should be considered a stronger than the other than the north wind blow us hard as he could put the more he blew the more closely did the traveler for his clock around him and unless the north wind gave up the tent in the song in the sky shine on me and immediately was alive to confess that the sun was the stronger of\",\n",
        "                    \"the nurse win and the song where they speak english with the stronger when the traveler came or not in the room clock they agreed that the one who first succeed in making the traveler take his clock off should be considered stronger than the other than the north wind blew as hard as he could put the more he blew the more closely did the turbo for his club around him and i left the list the nursery was over to confess that the song was the stronger of the two\",\n",
        "                    \"the nurse mean and the song world is putting which was the stronger when a traveler came along rough in a warm clock they agreed that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could the more he blew the more closely together for his clock around him and i left the nursery was obviously to confess that the song was the stronger of the two\",\n",
        "                    \"the nurse win and the sun was disputing which was the stronger when a traveler came along route in the warm clothes they are great that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely the doctor for his clock around him and i left and there's one game of the attempt in the sun in the sky shine at warmly and immediately to travel to the nurse when was over to confess that the sun was the stronger of the two\",\n",
        "                    \"the nurse win and the sun was disputing which was the stronger when a traveler came along route in the warm clothes they are great that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely the doctor for his clock around him and i left and there's one game of the attempt in the sun in the sky shine at warmly and immediately to travel to the nurse when was over to confess that the sun was the stronger of the two\",\n",
        "                    \"the north wind and the sun were disputing which was the stronger, when a traveler came along wrapped in a warm cloak. they agreed that the one who first succeeded in making the traveler take his cloak off should be considered stronger than the other. then the north wind blew as hard as he could, but the more he blew the more closely did the traveler fold his cloak around him; and at last the north wind gave up the attempt. then the sun shined out warmly, and immediately the traveler took off his cloak. and so the north wind was obliged to confess that the sun was the stronger of the two.\",\n",
        "                    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak they agreed that the one who first succeeded in making the traveler take his cloak off should be considered stronger than the other then the north wind blew as hard as he could but the more he blew the more closely did the traveler fold his cloak around him and at last the north wind gave up the attempt then the sun shined out warmly and immediately the traveler took off his cloak and so the north wind was obliged to confess that the sun was the stronger of the two\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "kO2-b7M_9YlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üåµ 2. WER (subj1, rep1, all text, original)**\n",
        "  - Full Text: North Wind and the Sun were disputing which was the stronger, when a traveler came along wrapped in a warm cloak. They agreed that the one who first succeeded in making the traveler take his cloak off should be considered stronger than the other. Then the North Wind blew as hard as he could, but the more he blew the more closely did the traveler fold his cloak around him; and at last the North Wind gave up the attempt. Then the Sun shined out warmly, and immediately the traveler took off his cloak. And so the North Wind was obliged to confess that the Sun was the stronger of the two.\n",
        "  \n",
        " - #reference12: small letters across the board without punctuations\n",
        "\n",
        " - #hypothesis9: same as original text with punctuations\n",
        " - #hypothesis10: small letters across the board with punctuations\n",
        " - #hypothesis11: small letters across the board without punctuations\n",
        " - #hypothesis12: small letters across the board without punctuations"
      ],
      "metadata": {
        "id": "jKK1eYa1ZIRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "import string\n",
        "\n",
        "reference_text = \"The North Wind and the Sun were disputing which was the stronger, when a traveler came along wrapped in a warm cloak. They agreed that the one who first succeeded in making the traveler take his cloak off should be considered stronger than the other. Then the North Wind blew as hard as he could, but the more he blew the more closely did the traveler fold his cloak around him; and at last the North Wind gave up the attempt. Then the Sun shined out warmly, and immediately the traveler took off his cloak. And so the North Wind was obliged to confess that the Sun was the stronger of the two.\"\n",
        "convert2small_reference = reference_text.lower()\n",
        "\n",
        "# Remove punctuation marks\n",
        "translator = str.maketrans(\"\", \"\", string.punctuation)\n",
        "cleaned_reference = convert2small_reference.translate(translator)\n",
        "\n",
        "# Tokenize the cleaned reference text\n",
        "token_prefinal = text_to_word_sequence(cleaned_reference)\n",
        "sent_convert = ' '.join(token_prefinal)\n",
        "print('Tokenizing Words after Cleaning Punctuations: %s' % sent_convert)"
      ],
      "metadata": {
        "id": "bLdsx7qf8urZ",
        "outputId": "f7755236-4291-48b7-87ae-225e1fec9212",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing Words after Cleaning Punctuations: the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak they agreed that the one who first succeeded in making the traveler take his cloak off should be considered stronger than the other then the north wind blew as hard as he could but the more he blew the more closely did the traveler fold his cloak around him and at last the north wind gave up the attempt then the sun shined out warmly and immediately the traveler took off his cloak and so the north wind was obliged to confess that the sun was the stronger of the two\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Original Full Text of 'The North Wind and the Sun' abbreviated as OFT\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install Levenshtein\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return round(wer, 2)  # Round the WER to two decimal places. >>return wer ÎùºÍ≥† code line Ïì∞Î©¥, longer decimal places for default\n",
        "\n",
        "# Calculate WER for each pair of texts\n",
        "reference_texts = [\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak they agreed that the one who first succeeded in making the traveler take his cloak off should be considered stronger than the other then the north wind blew as hard as he could but the more he blew the more closely did the traveler fold his cloak around him and at last the north wind gave up the attempt then the sun shined out warmly and immediately the traveler took off his cloak and so the north wind was obliged to confess that the sun was the stronger of the two\",\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak they agreed that the one who first succeeded in making the traveler take his cloak off should be considered stronger than the other then the north wind blew as hard as he could but the more he blew the more closely did the traveler fold his cloak around him and at last the north wind gave up the attempt then the sun shined out warmly and immediately the traveler took off his cloak and so the north wind was obliged to confess that the sun was the stronger of the two\",\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak they agreed that the one who first succeeded in making the traveler take his cloak off should be considered stronger than the other then the north wind blew as hard as he could but the more he blew the more closely did the traveler fold his cloak around him and at last the north wind gave up the attempt then the sun shined out warmly and immediately the traveler took off his cloak and so the north wind was obliged to confess that the sun was the stronger of the two\",\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak they agreed that the one who first succeeded in making the traveler take his cloak off should be considered stronger than the other then the north wind blew as hard as he could but the more he blew the more closely did the traveler fold his cloak around him and at last the north wind gave up the attempt then the sun shined out warmly and immediately the traveler took off his cloak and so the north wind was obliged to confess that the sun was the stronger of the two\",\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak they agreed that the one who first succeeded in making the traveler take his cloak off should be considered stronger than the other then the north wind blew as hard as he could but the more he blew the more closely did the traveler fold his cloak around him and at last the north wind gave up the attempt then the sun shined out warmly and immediately the traveler took off his cloak and so the north wind was obliged to confess that the sun was the stronger of the two\",\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak they agreed that the one who first succeeded in making the traveler take his cloak off should be considered stronger than the other then the north wind blew as hard as he could but the more he blew the more closely did the traveler fold his cloak around him and at last the north wind gave up the attempt then the sun shined out warmly and immediately the traveler took off his cloak and so the north wind was obliged to confess that the sun was the stronger of the two\",\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak they agreed that the one who first succeeded in making the traveler take his cloak off should be considered stronger than the other then the north wind blew as hard as he could but the more he blew the more closely did the traveler fold his cloak around him and at last the north wind gave up the attempt then the sun shined out warmly and immediately the traveler took off his cloak and so the north wind was obliged to confess that the sun was the stronger of the two\",\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak they agreed that the one who first succeeded in making the traveler take his cloak off should be considered stronger than the other then the north wind blew as hard as he could but the more he blew the more closely did the traveler fold his cloak around him and at last the north wind gave up the attempt then the sun shined out warmly and immediately the traveler took off his cloak and so the north wind was obliged to confess that the sun was the stronger of the two\"\n",
        "]\n",
        "\n",
        "hypothesis_texts = [\"the nurse wind and the sun world is building which was the stronger when a traveler came along work in a warm clock they are reset the one who first succeeded in making the traveler take his clock of should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely the traveler from his club around him and i lost the nursery and immediately go traveling was only\",\n",
        "                    \"the nursery and the sun world is putting which was stronger when i travel i came along work in a warm club they are really that the one who forced to succeed in making the traveler take his clock of should be considered stronger than the other in the nurse main blue as hard as he could put them away he blew the more closely did the traveler for his club around him and i lost the nursery nursery\",\n",
        "                    \"the nurse win and the song world is putting which was stronger when a traveler came around worked in the alarm clock they are really that the one who first succeed in making the traveler take his clothes off should be considered stronger than the other then the nurse wind blew as hard as he could but\",\n",
        "                    \"the nurse wind and the sun world is putting this was the stronger when a traveler came along with the warm clock they are read that the one who first succeeded in making the traveler take his clock off should be considered a stronger than the other than the north wind blow us hard as he could put the more he blew the more closely did the traveler for his clock around him and unless the north wind gave up the tent in the song in the sky shine on me and immediately was alive to confess that the sun was the stronger of\",\n",
        "                    \"the nurse win and the song where they speak english with the stronger when the traveler came or not in the room clock they agreed that the one who first succeed in making the traveler take his clock off should be considered stronger than the other than the north wind blew as hard as he could put the more he blew the more closely did the turbo for his club around him and i left the list the nursery was over to confess that the song was the stronger of the two\",\n",
        "                    \"the nurse mean and the song world is putting which was the stronger when a traveler came along rough in a warm clock they agreed that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could the more he blew the more closely together for his clock around him and i left the nursery was obviously to confess that the song was the stronger of the two\",\n",
        "                    \"the nurse win and the sun was disputing which was the stronger when a traveler came along route in the warm clothes they are great that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely the doctor for his clock around him and i left and there's one game of the attempt in the sun in the sky shine at warmly and immediately to travel to the nurse when was over to confess that the sun was the stronger of the two\",\n",
        "                    \"the nurse win and the sun was disputing which was the stronger when a traveler came along route in the warm clothes they are great that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely the doctor for his clock around him and i left and there's one game of the attempt in the sun in the sky shine at warmly and immediately to travel to the nurse when was over to confess that the sun was the stronger of the two\"\n",
        "]\n",
        "\n",
        "wer_values = []\n",
        "for reference, hypothesis in zip(reference_texts, hypothesis_texts):\n",
        "    wer = calculate_wer(reference, hypothesis)\n",
        "    wer_values.append(wer)\n",
        "\n",
        "# Create a DataFrame from the WER values\n",
        "df = pd.DataFrame(np.array(wer_values).reshape(-1, 1), columns=['WER'])\n",
        "df.index = [\"Full Text of 'The Nor {}\".format(i+1) for i in range(len(wer_values))]\n",
        "\n",
        "print(df)\n",
        "\n",
        "output_file = 'subj1_fulltext.xlsx'\n",
        "df.to_excel(output_file, index=False)"
      ],
      "metadata": {
        "id": "Mg470zPla7-s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a5ba2b5-e454-4671-a937-81d0b7f8531b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Levenshtein in /usr/local/lib/python3.10/dist-packages (0.21.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein) (3.1.1)\n",
            "                          WER\n",
            "Full Text of 'The Nor 1  0.46\n",
            "Full Text of 'The Nor 2  0.59\n",
            "Full Text of 'The Nor 3  0.65\n",
            "Full Text of 'The Nor 4  0.36\n",
            "Full Text of 'The Nor 5  0.43\n",
            "Full Text of 'The Nor 6  0.41\n",
            "Full Text of 'The Nor 7  0.35\n",
            "Full Text of 'The Nor 8  0.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üåµ  3. STT (subj1, rep1, sentence1, original)**"
      ],
      "metadata": {
        "id": "TGzZW3DS8aw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "import speech_recognition as sr\n",
        "import os\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "    lowercase_text = text.lower()  # Convert the text to lowercase\n",
        "\n",
        "    return lowercase_text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"/content/sample_data/subj1_sent_8original\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bxfabYsAEwk",
        "outputId": "7224708b-2b99-42d8-acf7-1de9dba9184c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "File: PYI_1_5_1.wav\n",
            "Text: the nurse win and the song where they speak english with the stronger when the traveler came or not in the wrong\n",
            "Word Count: 22\n",
            "\n",
            "File: PYI_1_4_1.wav\n",
            "Text: the nurse wind and the sun world is putting this was the stronger when a traveller came out of work in the warm clock\n",
            "Word Count: 24\n",
            "\n",
            "File: PYI_1_2_1.wav\n",
            "Text: the nursery and the sun world is putting which was stronger when i travel i came along work in a warm\n",
            "Word Count: 21\n",
            "\n",
            "File: PYI_1_6_1.wav\n",
            "Text: the nurse mean and the song world is putting which was the stronger when a traveler came along rough in a warm clock\n",
            "Word Count: 23\n",
            "\n",
            "File: PYI_1_8_1.wav\n",
            "Text: the north wind and the sun world is building which was the stronger when a traveler came or not in a warm\n",
            "Word Count: 22\n",
            "\n",
            "File: PYI_1_1_1.wav\n",
            "Text: the nurse wind and the sun world is building which was the stronger when a traveler came along work in a warm clock\n",
            "Word Count: 23\n",
            "\n",
            "File: PYI_1_3_1.wav\n",
            "Text: the nurse win and the song world is putting which was stronger when a traveler came around worked in the alarm clock\n",
            "Word Count: 22\n",
            "\n",
            "File: PYI_1_7_1.wav\n",
            "Text: the nurse win and the sun was disputing which was the stronger when a traveler came along route in the warm clothes\n",
            "Word Count: 22\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üåµ  4 WER (subj1, rep1, sentence1, original)**"
      ],
      "metadata": {
        "id": "-vauZFNEZVDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return round(wer, 2)  # Round the WER to two decimal places. >>return wer ÎùºÍ≥† code line Ïì∞Î©¥, longer decimal places for default\n",
        "\n",
        "# Calculate WER for each pair of texts\n",
        "reference_texts = [\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak \",\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak \",\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak \",\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak \",\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak \",\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak \",\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak \",\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak \",\n",
        "]\n",
        "\n",
        "hypothesis_texts = [\"the nurse wind and the sun world is building which was the stronger when a traveler came along work in a warm clock\",\n",
        "                    \"the nursery and the sun world is putting which was stronger when i travel i came along work in a warm\",\n",
        "                    \"the nurse win and the song world is putting which was stronger when a traveler came around worked in the alarm clock\",\n",
        "                    \"the nurse wind and the sun world is putting this was the stronger when a traveller came out of work in the warm clock\",\n",
        "                    \"the nurse win and the song where they speak english with the stronger when the traveler came or not in the wrong\",\n",
        "                    \"the nurse mean and the song world is putting which was the stronger when a traveler came along rough in a warm clock\",\n",
        "                    \"the nurse win and the sun was disputing which was the stronger when a traveler came along route in the warm clothes\",\n",
        "                    \"the north wind and the sun world is building which was the stronger when a traveler came or not in a warm\"\n",
        "]\n",
        "\n",
        "wer_values = []\n",
        "for reference, hypothesis in zip(reference_texts, hypothesis_texts):\n",
        "    wer = calculate_wer(reference, hypothesis)\n",
        "    wer_values.append(wer)\n",
        "\n",
        "# Create a DataFrame from the WER values\n",
        "df = pd.DataFrame(np.array(wer_values).reshape(-1, 1), columns=['WER'])\n",
        "df.index = [\"Sentence1 of 'the North Wind and the Sun'{}\".format(i+1) for i in range(len(wer_values))]\n",
        "\n",
        "print(df)\n",
        "\n",
        "output_file = 'subj1_sentence1.xlsx'\n",
        "df.to_excel(output_file, index=False)"
      ],
      "metadata": {
        "id": "dfaro8QIaB0x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "819461dc-ffc8-4b5b-9cd8-e97e6467d925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             WER\n",
            "Sentence1 of 'the North Wind and the Sun'1  0.27\n",
            "Sentence1 of 'the North Wind and the Sun'2  0.50\n",
            "Sentence1 of 'the North Wind and the Sun'3  0.55\n",
            "Sentence1 of 'the North Wind and the Sun'4  0.50\n",
            "Sentence1 of 'the North Wind and the Sun'5  0.64\n",
            "Sentence1 of 'the North Wind and the Sun'6  0.36\n",
            "Sentence1 of 'the North Wind and the Sun'7  0.27\n",
            "Sentence1 of 'the North Wind and the Sun'8  0.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üåµ  5. STT (subj1, rep1, main clause, original)**\n",
        "###üê• **original sentence divided into main clause**"
      ],
      "metadata": {
        "id": "wBChSHExcWf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "import speech_recognition as sr\n",
        "import os\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "    lowercase_text = text.lower()  # Convert the text to lowercase\n",
        "\n",
        "    return lowercase_text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"/content/sample_data/subj1_main_8original\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")"
      ],
      "metadata": {
        "id": "4YCPK_9YcdkQ",
        "outputId": "b3ac8f0e-9a67-429c-e88e-37086b89ce02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "File: PYI_1_5_1_main.wav\n",
            "Text: the nurse wind and the sun world is building which was the stronger\n",
            "Word Count: 13\n",
            "\n",
            "File: PYI_1_6_1_main.wav\n",
            "Text: the nurse mean and the song world is putting which was the stronger\n",
            "Word Count: 13\n",
            "\n",
            "File: PYI_1_3_1_main.wav\n",
            "Text: the nurse win and the song world is putting which was stronger\n",
            "Word Count: 12\n",
            "\n",
            "File: PYI_1_2_1_main.wav\n",
            "Text: the nursery and the sun world is putting which was stronger\n",
            "Word Count: 11\n",
            "\n",
            "File: PYI_1_8_1_main.wav\n",
            "Text: the north wind and the sun world is building which was the stronger\n",
            "Word Count: 13\n",
            "\n",
            "File: PYI_1_7_1_main.wav\n",
            "Text: the nurse win and the sun was disputing which was the stronger\n",
            "Word Count: 12\n",
            "\n",
            "File: PYI_1_1_1_main.wav\n",
            "Text: the nurse wind and the sun world is building which was the stronger\n",
            "Word Count: 13\n",
            "\n",
            "File: PYI_1_4_1_main.wav\n",
            "Text: the nurse wind and the sun world is putting this was the stronger\n",
            "Word Count: 13\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üåµ  6. WER (subj1, rep1, main clause, original)**\n",
        "  - üÜò Alert: In this code, I've imported the numpy library as np and used the reshape function to convert originalsentence1 into a 2D array with dimensions (8, 1). This ensures that the shape of the values matches the implied shape based on the indices and columns specified for the DataFrame."
      ],
      "metadata": {
        "id": "WLdGxED_aGs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return round(wer, 2)  # Round the WER to two decimal places. >>return wer ÎùºÍ≥† code line Ïì∞Î©¥, longer decimal places for default\n",
        "\n",
        "# Calculate WER for each pair of texts\n",
        "reference_texts = [\n",
        "    \"the north wind and the sun were disputing which was the stronger\",\n",
        "    \"the north wind and the sun were disputing which was the stronger\",\n",
        "    \"the north wind and the sun were disputing which was the stronger\",\n",
        "    \"the north wind and the sun were disputing which was the stronger\",\n",
        "    \"the north wind and the sun were disputing which was the stronger\",\n",
        "    \"the north wind and the sun were disputing which was the stronger\",\n",
        "    \"the north wind and the sun were disputing which was the stronger\",\n",
        "    \"the north wind and the sun were disputing which was the stronger\"\n",
        "]\n",
        "\n",
        "hypothesis_texts = [\n",
        "    \"the nurse wind and the sun world is building which was the stronger\",\n",
        "    \"the nursery and the sun world is putting which was stronger\",\n",
        "    \"the nurse win and the song world is putting which was stronger\",\n",
        "    \"the nurse wind and the sun world is putting this was the stronger\",\n",
        "    \"the nurse wind and the sun world is building which was the stronger\",\n",
        "    \"the nurse mean and the song world is putting which was the stronger\",\n",
        "    \"the nurse win and the sun was disputing which was the stronger\",\n",
        "    \"the north wind and the sun world is building which was the stronger\"\n",
        "]\n",
        "\n",
        "wer_values = []\n",
        "for reference, hypothesis in zip(reference_texts, hypothesis_texts):\n",
        "    wer = calculate_wer(reference, hypothesis)\n",
        "    wer_values.append(wer)\n",
        "\n",
        "# Create a DataFrame from the WER values\n",
        "df = pd.DataFrame(np.array(wer_values).reshape(-1, 1), columns=['WER'])\n",
        "df.index = ['Main Clause of Sentence1{}'.format(i+1) for i in range(len(wer_values))]\n",
        "\n",
        "print(df)\n",
        "\n",
        "output_file = 'subj1_mainclause.xlsx'\n",
        "df.to_excel(output_file, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQtLSJV-9y8u",
        "outputId": "72344043-34c4-44a4-a09e-61e99387dc98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            WER\n",
            "Main Clause of Sentence11  0.33\n",
            "Main Clause of Sentence12  0.50\n",
            "Main Clause of Sentence13  0.58\n",
            "Main Clause of Sentence14  0.42\n",
            "Main Clause of Sentence15  0.33\n",
            "Main Clause of Sentence16  0.50\n",
            "Main Clause of Sentence17  0.25\n",
            "Main Clause of Sentence18  0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üåµ  7. STT (subj1, rep1, subordinate clause, original)**\n",
        "###üê• **original sentence divided into subordinate clause**"
      ],
      "metadata": {
        "id": "aRdTVoFIdrN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "import speech_recognition as sr\n",
        "import os\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "    lowercase_text = text.lower()  # Convert the text to lowercase\n",
        "\n",
        "    return lowercase_text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"/content/sample_data/subj1_subordinate_8original\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")"
      ],
      "metadata": {
        "id": "qqWhaWHfdoqd",
        "outputId": "c663d423-503e-42e5-be95-9144891ae19b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "File: PYI_1_6_1_subordinate.wav\n",
            "Text: when a traveler came along rough in a warm clock\n",
            "Word Count: 10\n",
            "\n",
            "File: PYI_1_2_1_subordinate.wav\n",
            "Text: when a turtle that came along with in a warm\n",
            "Word Count: 10\n",
            "\n",
            "File: PYI_1_5_1_subordinate.wav\n",
            "Text: when the traveler came or not in a room clock\n",
            "Word Count: 10\n",
            "\n",
            "File: PYI_1_8_1_subordinate.wav\n",
            "Text: when a traveler came or not wrap in a warm\n",
            "Word Count: 10\n",
            "\n",
            "File: PYI_1_1_1_subordinate.wav\n",
            "Text: atlanta traveler came along work in a warm clock\n",
            "Word Count: 9\n",
            "\n",
            "File: PYI_1_7_1_subordinate.wav\n",
            "Text: when a traveler came along rough in the warm clothes\n",
            "Word Count: 10\n",
            "\n",
            "File: PYI_1_3_1_subordinate.wav\n",
            "Text: when a traveler came around worked in the alarm clock\n",
            "Word Count: 10\n",
            "\n",
            "File: PYI_1_4_1_subordinate.wav\n",
            "Text: when a traveller came out of work in the warm clock\n",
            "Word Count: 11\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üåµ  8. WER (subj1, rep1, subordinate clause, original)**"
      ],
      "metadata": {
        "id": "pj5h1HY9aQnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return round(wer, 2)  # Round the WER to two decimal places. >>return wer ÎùºÍ≥† code line Ïì∞Î©¥, longer decimal places for default\n",
        "\n",
        "# Calculate WER for each pair of texts\n",
        "reference_texts = [\n",
        "    \"when a traveler came along wrapped in a warm cloak\",\n",
        "    \"when a traveler came along wrapped in a warm cloak\",\n",
        "    \"when a traveler came along wrapped in a warm cloak\",\n",
        "    \"when a traveler came along wrapped in a warm cloak\",\n",
        "    \"when a traveler came along wrapped in a warm cloak\",\n",
        "    \"when a traveler came along wrapped in a warm cloak\",\n",
        "    \"when a traveler came along wrapped in a warm cloak\",\n",
        "    \"when a traveler came along wrapped in a warm cloak\"\n",
        "]\n",
        "\n",
        "hypothesis_texts = [\n",
        "    \"atlanta traveler came along work in a warm clock\",\n",
        "    \"when a turtle that came along with in a warm\",\n",
        "    \"when a traveler came around worked in the alarm clock\",\n",
        "    \"when a traveller came out of work in the warm clock\",\n",
        "    \"when the traveler came or not in a room clock\",\n",
        "    \"when a traveler came along rough in a warm clock\",\n",
        "    \"when a traveler came along rough in the warm clothes\",\n",
        "    \"when a traveler came or not wrap in a warm\"\n",
        "]\n",
        "\n",
        "wer_values = []\n",
        "for reference, hypothesis in zip(reference_texts, hypothesis_texts):\n",
        "    wer = calculate_wer(reference, hypothesis)\n",
        "    wer_values.append(wer)\n",
        "\n",
        "# Create a DataFrame from the WER values\n",
        "df = pd.DataFrame(np.array(wer_values).reshape(-1, 1), columns=['WER'])\n",
        "df.index = ['Subordinate Clause of Sentence1{}'.format(i+1) for i in range(len(wer_values))]\n",
        "print(df)\n",
        "\n",
        "output_file = 'subj1_subordinateclause.xlsx'\n",
        "df.to_excel(output_file, index=False)"
      ],
      "metadata": {
        "id": "So1kD9T1Kms9",
        "outputId": "527f92a5-3c22-4bf1-d371-eccef5e04c13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                  WER\n",
            "Subordinate Clause of Sentence11  0.4\n",
            "Subordinate Clause of Sentence12  0.4\n",
            "Subordinate Clause of Sentence13  0.5\n",
            "Subordinate Clause of Sentence14  0.6\n",
            "Subordinate Clause of Sentence15  0.5\n",
            "Subordinate Clause of Sentence16  0.2\n",
            "Subordinate Clause of Sentence17  0.3\n",
            "Subordinate Clause of Sentence18  0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üåµ  9. STT (subj1, rep1, last 4 words, original)**"
      ],
      "metadata": {
        "id": "mIwCsbE4aT6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "import speech_recognition as sr\n",
        "import os\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "    lowercase_text = text.lower()  # Convert the text to lowercase\n",
        "\n",
        "    return lowercase_text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"/content/sample_data/subj1_last4words_8original\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")"
      ],
      "metadata": {
        "id": "xEMlSDv_jh87",
        "outputId": "6c850d78-7635-474a-9682-ed68098d2af7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "File: PYI_1_4_1_last4words.wav\n",
            "Text: in the warm clock\n",
            "Word Count: 4\n",
            "\n",
            "File: PYI_1_8_1_last4words.wav\n",
            "Text: in the warm club\n",
            "Word Count: 4\n",
            "\n",
            "File: PYI_1_3_1_last4words.wav\n",
            "Text: in the alarm clock\n",
            "Word Count: 4\n",
            "\n",
            "File: PYI_1_5_1_last4words.wav\n",
            "Text: in a room\n",
            "Word Count: 3\n",
            "\n",
            "File: PYI_1_2_1_last4words.wav\n",
            "Text: enough alarm\n",
            "Word Count: 2\n",
            "\n",
            "File: PYI_1_7_1_last4words.wav\n",
            "Text: in the warm club\n",
            "Word Count: 4\n",
            "\n",
            "File: PYI_1_6_1_last4words.wav\n",
            "Text: in a warm club\n",
            "Word Count: 4\n",
            "\n",
            "File: PYI_1_1_1_last4words.wav\n",
            "Text: in alarm clock\n",
            "Word Count: 3\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üåµ 10. WER (subj1, rep1, last 4 words, original)**"
      ],
      "metadata": {
        "id": "MTOM2frKaaED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return round(wer, 2)  # Round the WER to two decimal places. >>return wer ÎùºÍ≥† code line Ïì∞Î©¥, longer decimal places for default\n",
        "\n",
        "# Calculate WER for each pair of texts\n",
        "reference_texts = [\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "]\n",
        "\n",
        "hypothesis_texts = [\n",
        "    \"in alarm clock\",\n",
        "    \"enough alarm\",\n",
        "    \"in the alarm clock\",\n",
        "    \"in the warm clock\",\n",
        "    \"in a room\",\n",
        "    \"in a warm club\",\n",
        "    \"in the warm club\",\n",
        "    \"in the warm club\"\n",
        "]\n",
        "\n",
        "wer_values = []\n",
        "for reference, hypothesis in zip(reference_texts, hypothesis_texts):\n",
        "    wer = calculate_wer(reference, hypothesis)\n",
        "    wer_values.append(wer)\n",
        "\n",
        "# Create a DataFrame from the WER values\n",
        "df = pd.DataFrame(np.array(wer_values).reshape(-1, 1), columns=['WER'])\n",
        "df.index = ['Subordinate Clause of Sentence1{}'.format(i+1) for i in range(len(wer_values))]\n",
        "print(df)\n",
        "\n",
        "output_file = 'subj1_last4words.xlsx'\n",
        "df.to_excel(output_file, index=False)"
      ],
      "metadata": {
        "id": "ngwyegGUG17_",
        "outputId": "5edc7477-68a6-4345-e02b-d9b3adc88321",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                   WER\n",
            "Subordinate Clause of Sentence11  0.75\n",
            "Subordinate Clause of Sentence12  1.00\n",
            "Subordinate Clause of Sentence13  0.75\n",
            "Subordinate Clause of Sentence14  0.50\n",
            "Subordinate Clause of Sentence15  0.50\n",
            "Subordinate Clause of Sentence16  0.25\n",
            "Subordinate Clause of Sentence17  0.50\n",
            "Subordinate Clause of Sentence18  0.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**üêπ <font color = 'brown'> Noise cancellation and compression applied** ‚§µÔ∏è"
      ],
      "metadata": {
        "id": "20Agm7Dj7dJi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üêπ <font color = 'green'> google STT (SpeechRecognition package) applied to a list of compressed wav. files and their corresponding word count** ‚§µÔ∏è"
      ],
      "metadata": {
        "id": "bNexgs_58cLh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üêô **1. Transform original (rep1_sentence1) to denoised and compressed wav. format**"
      ],
      "metadata": {
        "id": "sruS4_UOUSKx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CQ6Nn8tycRf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# subj1_rep1_sentence1_original to denoised and comprsssed format\n",
        "\n",
        "!pip install librosa\n",
        "!pip install pydub\n",
        "!pip install numpy\n",
        "\n",
        "import os\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "\n",
        "from pydub import AudioSegment\n",
        "from pydub.effects import compress_dynamic_range\n",
        "\n",
        "def reduce_noise(audio_file, threshold=0.02):\n",
        "    y, sr = librosa.load(audio_file)\n",
        "\n",
        "    # Compute the short-term power of the audio\n",
        "    power = np.abs(librosa.stft(y))**2\n",
        "\n",
        "    # Set values below the threshold to zero\n",
        "    mask = power < threshold * np.max(power)\n",
        "    power[mask] = 0\n",
        "\n",
        "    # Reconstruct the audio\n",
        "    y_clean = librosa.istft(np.sqrt(power) * np.exp(1j * np.angle(librosa.stft(y))))\n",
        "\n",
        "    return y_clean, sr\n",
        "\n",
        "def compress_audio(audio_file, threshold=-20.0, ratio=4.0):\n",
        "    audio = AudioSegment.from_file(audio_file)\n",
        "\n",
        "    # Apply dynamic range compression\n",
        "    compressed_audio = compress_dynamic_range(audio, threshold=threshold, ratio=ratio)\n",
        "\n",
        "    return compressed_audio, audio.frame_rate\n",
        "\n",
        "# Path to the folder containing the sound files\n",
        "folder_path = \"/content/sample_data/subj1_sent_8original\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        # Apply noise reduction\n",
        "        denoised_audio, sr = reduce_noise(audio_file, threshold=0.02)\n",
        "\n",
        "        # Apply dynamic range compression\n",
        "        compressed_audio, sr = compress_audio(audio_file, threshold=-20.0, ratio=4.0)\n",
        "\n",
        "        # Save the denoised audio to a new file\n",
        "        denoised_filename = \"denoised_\" + filename\n",
        "        sf.write(denoised_filename, denoised_audio, sr)\n",
        "\n",
        "        # Save the compressed audio to a new file\n",
        "        compressed_filename = \"compressed_\" + filename\n",
        "        compressed_audio.export(compressed_filename, format=\"wav\")\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Denoised audio saved as: {denoised_filename}\")\n",
        "        print(f\"Compressed audio saved as: {compressed_filename}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVvvO0wJAofb",
        "outputId": "402f0601-37bc-4361-a554-22b701aa5a95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.0.post2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch<1.7,>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.5.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.2)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.5)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa) (23.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa) (2.27.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n",
            "File: PYI_1_4_1.wav\n",
            "Denoised audio saved as: denoised_PYI_1_4_1.wav\n",
            "Compressed audio saved as: compressed_PYI_1_4_1.wav\n",
            "\n",
            "File: PYI_1_8_1.wav\n",
            "Denoised audio saved as: denoised_PYI_1_8_1.wav\n",
            "Compressed audio saved as: compressed_PYI_1_8_1.wav\n",
            "\n",
            "File: PYI_1_1_1.wav\n",
            "Denoised audio saved as: denoised_PYI_1_1_1.wav\n",
            "Compressed audio saved as: compressed_PYI_1_1_1.wav\n",
            "\n",
            "File: PYI_1_7_1.wav\n",
            "Denoised audio saved as: denoised_PYI_1_7_1.wav\n",
            "Compressed audio saved as: compressed_PYI_1_7_1.wav\n",
            "\n",
            "File: PYI_1_3_1.wav\n",
            "Denoised audio saved as: denoised_PYI_1_3_1.wav\n",
            "Compressed audio saved as: compressed_PYI_1_3_1.wav\n",
            "\n",
            "File: PYI_1_5_1.wav\n",
            "Denoised audio saved as: denoised_PYI_1_5_1.wav\n",
            "Compressed audio saved as: compressed_PYI_1_5_1.wav\n",
            "\n",
            "File: PYI_1_2_1.wav\n",
            "Denoised audio saved as: denoised_PYI_1_2_1.wav\n",
            "Compressed audio saved as: compressed_PYI_1_2_1.wav\n",
            "\n",
            "File: PYI_1_6_1.wav\n",
            "Denoised audio saved as: denoised_PYI_1_6_1.wav\n",
            "Compressed audio saved as: compressed_PYI_1_6_1.wav\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üêô 2. STT (subj1, rep1, all text, compressed)**"
      ],
      "metadata": {
        "id": "kRaYMInjYMsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "\n",
        "import os\n",
        "import speech_recognition as sr\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "\n",
        "    return text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"/content/sample_data/subj1_para_8compressed\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvW9ttq68bWh",
        "outputId": "57b25549-8999-4bdb-a8a9-297e560a53b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "File: compressed_subj1_session1_rep4.wav\n",
            "Text: the nurse wind and the sun world is putting this was the stronger when a traveler came along with the warm clock they are read that the one who first succeeded in making the traveler take his clock off should be considered a stronger than the other than the north wind blow us hard as he could put the more he blew the more closely did The Traveler for his clock around him and unless the north wind gave up the tent in the song in the sky shine on me and immediately was alive to confess that the sun was the stronger of\n",
            "Word Count: 104\n",
            "\n",
            "File: compressed_subj1_session1_rep6.wav\n",
            "Text: the nurse mean and the song world is putting which was the stronger when a traveler came along rough in a warm clock they agreed that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could the more he blew the more closely together for his clock around him and I left the nursery was obviously to confess that the song was the stronger of the two\n",
            "Word Count: 87\n",
            "\n",
            "File: compressed_subj1_session1_rep8.wav\n",
            "Text: the nurse win and the sun was disputing which was the stronger when a traveler came along Route in the warm clothes they are great that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely the doctor for his clock around him and I left and there's one game of the attempt in the Sun in the sky shine at warmly and immediately to travel to the nurse when was over to confess that the sun was the stronger of the two\n",
            "Word Count: 111\n",
            "\n",
            "File: compressed_subj1_session1_rep1.wav\n",
            "Text: the nurse wind and the sun world is building which was the stronger when a traveler came along work in a warm clock they are reset the one who first succeeded in making the traveler take his clock of should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely The Traveler from his Club around him and I lost the nursery and immediately go traveling was only\n",
            "Word Count: 82\n",
            "\n",
            "File: compressed_subj1_session1_rep5.wav\n",
            "Text: the nurse win and the song where they speak English with the stronger when the traveler came or not in the room clock they agreed that the one who first succeed in making the traveler take his clock off should be considered stronger than the other than the north wind blew as hard as he could put the more he blew the more closely did the turbo for his Club around him and I left the list the nursery was over to confess that the song was the stronger of the two\n",
            "Word Count: 92\n",
            "\n",
            "File: compressed_subj1_session1_rep7.wav\n",
            "Text: the nurse win and the sun was disputing which was the stronger when a traveler came along Route in the warm clothes they are great that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely the doctor for his clock around him and I left and there's one game of the attempt in the Sun in the sky shine at warmly and immediately to travel to the nurse when was over to confess that the sun was the stronger of the two\n",
            "Word Count: 111\n",
            "\n",
            "File: compressed_subj1_session1_rep3.wav\n",
            "Text: the nurse win and the song world is putting which was Stronger when a traveler came around worked in the alarm clock they are really that the one who first succeed in making the traveler take his clothes off should be considered stronger than the other then the nurse wind blew as hard as he could but\n",
            "Word Count: 57\n",
            "\n",
            "File: compressed_subj1_session1_rep2.wav\n",
            "Text: the nursery and the sun world is putting which was Stronger when I travel I came along work in a warm Club they are really that the one who forced to succeed in making the traveler take his clock of should be considered stronger than the other in the nurse main blue as hard as he could put them away he blew the more closely did The Traveler for his Club around him and I lost the nursery nursery\n",
            "Word Count: 79\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üêô **3. WER (subj1, rep1, all text, compressed)**"
      ],
      "metadata": {
        "id": "XvldsYzJYg5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Temp\n",
        "\n",
        "!pip install python-Levenshtein\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return wer\n",
        "\n",
        "# Example usage\n",
        "reference_text1 = \"\"\n",
        "hypothesis_text1 = \"\"\n",
        "CFT_wer1 = calculate_wer(reference_text1, hypothesis_text1)\n",
        "print(f\"Word Error Rate (WER): {CFT_wer1}\")\n",
        "\n",
        "reference_text2 = \"\"\n",
        "hypothesis_text2 = \"\"\n",
        "CFT_wer2 = calculate_wer(reference_text2, hypothesis_text2)\n",
        "print(f\"Word Error Rate (WER): {CFT_wer2}\")\n",
        "\n",
        "reference_text3 = \"\"\n",
        "hypothesis_text3 = \"\"\n",
        "CFT_wer3 = calculate_wer(reference_text3, hypothesis_text3)\n",
        "print(f\"Word Error Rate (WER): {CFT_wer3}\")\n",
        "\n",
        "reference_text4 = \"\"\n",
        "hypothesis_text4 = \"\"\n",
        "CFT_wer4 = calculate_wer(reference_text4, hypothesis_text4)\n",
        "print(f\"Word Error Rate (WER): {CFT_wer4}\")\n",
        "\n",
        "reference_text5 = \"\"\n",
        "hypothesis_text5 = \"\"\n",
        "CFT_wer5 = calculate_wer(reference_text5, hypothesis_text5)\n",
        "print(f\"Word Error Rate (WER): {CFT_wer5}\")\n",
        "\n",
        "reference_text6 = \"\"\n",
        "hypothesis_text6 = \"\"\n",
        "CFT_wer6 = calculate_wer(reference_text6, hypothesis_text6)\n",
        "print(f\"Word Error Rate (WER): {CFT_wer6}\")\n",
        "\n",
        "reference_text7 = \"\"\n",
        "hypothesis_text7 = \"\"\n",
        "CFT_wer7 = calculate_wer(reference_text7, hypothesis_text7)\n",
        "print(f\"Word Error Rate (WER): {CFT_wer7}\")\n",
        "\n",
        "reference_text8 = \"\"\n",
        "hypothesis_text8 = \"\"\n",
        "CFT_wer8 = calculate_wer(reference_text8, hypothesis_text8)\n",
        "print(f\"Word Error Rate (WER): {CFT_wer8}\")"
      ],
      "metadata": {
        "id": "sCZR8Gwtz4S9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üêô **4. STT (subject1, rep1, sent1, compressed)**"
      ],
      "metadata": {
        "id": "S3dAP_qMU1ZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subject1_sentence1_compressed\n",
        "!pip install SpeechRecognition\n",
        "\n",
        "import os\n",
        "import speech_recognition as sr\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "\n",
        "    return text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"/content/sample_data/subj1_sent_8compressed\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0WCBGRGC7Gi",
        "outputId": "0bf7228b-892c-4b16-8549-fe2e4d0e107b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "File: compressed_PYI_1_1_1.wav\n",
            "Text: the nurse wind and the sun world is building which was the stronger when a traveler came along work in a warm clock\n",
            "Word Count: 23\n",
            "\n",
            "File: compressed_PYI_1_8_1.wav\n",
            "Text: The North Wind and the sun world is building which was the stronger when a traveler came or not in a warm\n",
            "Word Count: 22\n",
            "\n",
            "File: compressed_PYI_1_5_1.wav\n",
            "Text: the nurse win and the song where they speak English with the stronger when the traveler came or not in the wrong\n",
            "Word Count: 22\n",
            "\n",
            "File: compressed_PYI_1_4_1.wav\n",
            "Text: the nurse wind and the sun world is putting this was the stronger when a Traveller came out of work in the warm clock\n",
            "Word Count: 24\n",
            "\n",
            "File: compressed_PYI_1_3_1.wav\n",
            "Text: the nurse win and the song world is putting which was Stronger when a traveler came around worked in the alarm clock\n",
            "Word Count: 22\n",
            "\n",
            "File: compressed_PYI_1_6_1.wav\n",
            "Text: the nurse mean and the song world is putting which was the stronger when a traveler came along rough in a warm clock\n",
            "Word Count: 23\n",
            "\n",
            "File: compressed_PYI_1_2_1.wav\n",
            "Text: the nursery and the sun world is putting which was Stronger when I travel I came along work in a warm\n",
            "Word Count: 21\n",
            "\n",
            "File: compressed_PYI_1_7_1.wav\n",
            "Text: the nurse win and the sun was disputing which was the stronger when a traveler came along Route in the warm clothes\n",
            "Word Count: 22\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üêô **5. WER (subject1, rep1, sent1, compressed)**"
      ],
      "metadata": {
        "id": "L3nU8_fBVGxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#subj1_sent_rep1_sentence1_compressed\n",
        "\n",
        "!pip install python-Levenshtein\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return wer\n",
        "\n",
        "# Example usage\n",
        "reference_text1 = \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text1 = \"the nurse wind and the sun world is building which was the stronger when a traveler came along work in a warm clock\"\n",
        "wer1 = calculate_wer(reference_text1, hypothesis_text1)\n",
        "print(f\"Word Error Rate (WER): {wer1}\")\n",
        "\n",
        "reference_text2 = \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text2 = \"the nursery and the sun world is putting which was Stronger when I travel I came along work in a warm\"\n",
        "wer2 = calculate_wer(reference_text2, hypothesis_text2)\n",
        "print(f\"Word Error Rate (WER): {wer2}\")\n",
        "\n",
        "reference_text3 = \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text3 = \"the nurse win and the song world is putting which was Stronger when a traveler came around worked in the alarm clock\"\n",
        "wer3 = calculate_wer(reference_text3, hypothesis_text3)\n",
        "print(f\"Word Error Rate (WER): {wer3}\")\n",
        "\n",
        "reference_text4 = \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text4 = \"the nurse wind and the sun world is putting this was the stronger when a Traveller came out of work in the warm clock\"\n",
        "wer4 = calculate_wer(reference_text4, hypothesis_text4)\n",
        "print(f\"Word Error Rate (WER): {wer4}\")\n",
        "\n",
        "reference_text5 = \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text5 = \"the nurse win and the song where they speak English with the stronger when the traveler came or not in the wrong\"\n",
        "wer5 = calculate_wer(reference_text5, hypothesis_text5)\n",
        "print(f\"Word Error Rate (WER): {wer5}\")\n",
        "\n",
        "reference_text6 = \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text6 = \"the nurse mean and the song world is putting which was the stronger when a traveler came along rough in a warm clock\"\n",
        "wer6 = calculate_wer(reference_text6, hypothesis_text6)\n",
        "print(f\"Word Error Rate (WER): {wer6}\")\n",
        "\n",
        "reference_text7 = \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text7 = \"the nurse win and the sun was disputing which was the stronger when a traveler came along Route in the warm clothes\"\n",
        "wer7 = calculate_wer(reference_text7, hypothesis_text7)\n",
        "print(f\"Word Error Rate (WER): {wer7}\")\n",
        "\n",
        "reference_text8 = \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text8 = \"the North Wind and the sun world is building which was the stronger when a traveler came or not in a warm\"\n",
        "wer8 = calculate_wer(reference_text8, hypothesis_text8)\n",
        "print(f\"Word Error Rate (WER): {wer8}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MR36rYAiGlI5",
        "outputId": "d23ed2ce-d981-497f-9b05-178c29b694e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python_Levenshtein-0.21.1-py3-none-any.whl (9.4 kB)\n",
            "Collecting Levenshtein==0.21.1 (from python-Levenshtein)\n",
            "  Downloading Levenshtein-0.21.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=2.3.0 (from Levenshtein==0.21.1->python-Levenshtein)\n",
            "  Downloading rapidfuzz-3.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.21.1 python-Levenshtein-0.21.1 rapidfuzz-3.1.1\n",
            "Word Error Rate (WER): 0.2727272727272727\n",
            "Word Error Rate (WER): 0.5454545454545454\n",
            "Word Error Rate (WER): 0.5909090909090909\n",
            "Word Error Rate (WER): 0.5\n",
            "Word Error Rate (WER): 0.6363636363636364\n",
            "Word Error Rate (WER): 0.36363636363636365\n",
            "Word Error Rate (WER): 0.2727272727272727\n",
            "Word Error Rate (WER): 0.36363636363636365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üêô **6. STT (subject1, rep1, main clause, compressed)**\n",
        "###üê• **compressed sentence divided into main clause**"
      ],
      "metadata": {
        "id": "_7_fg4iOfNKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "\n",
        "import os\n",
        "import speech_recognition as sr\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "\n",
        "    return text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"/content/sample_data/subj1_compressed_main\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")"
      ],
      "metadata": {
        "id": "VJ5boQTRfP4p",
        "outputId": "c8d0d48d-b3a2-4909-d6f1-70eef35c9f44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "File: compressed_PYI_1_6_1_main.wav\n",
            "Text: the nurse mean and the song world is putting which was the stronger\n",
            "Word Count: 13\n",
            "\n",
            "File: compressed_PYI_1_7_1_main.wav\n",
            "Text: the nurse win and the sun was disputing which was the stronger\n",
            "Word Count: 12\n",
            "\n",
            "File: compressed_PYI_1_3_1_main.wav\n",
            "Text: the nurse win and the song world is putting which was Stronger\n",
            "Word Count: 12\n",
            "\n",
            "File: compressed_PYI_1_2_1_main.wav\n",
            "Text: the nursery and the sun world is putting which was Stronger\n",
            "Word Count: 11\n",
            "\n",
            "File: compressed_PYI_1_5_1_main.wav\n",
            "Text: the nurse wind and the sun world is building which was the stronger\n",
            "Word Count: 13\n",
            "\n",
            "File: compressed_PYI_1_8_1_main.wav\n",
            "Text: The North Wind and the sun world is building which was the stronger\n",
            "Word Count: 13\n",
            "\n",
            "File: compressed_PYI_1_4_1_main.wav\n",
            "Text: the nurse wind and the sun world is putting this was the stronger\n",
            "Word Count: 13\n",
            "\n",
            "File: compressed_PYI_1_1_1_main.wav\n",
            "Text: the nurse wind and the sun world is building which was the stronger\n",
            "Word Count: 13\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üêô **7. WER (subject1, rep1, main clause, compressed)**"
      ],
      "metadata": {
        "id": "YLYxi0CkVYMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#subj1_sent_rep1_compressed_main\n",
        "\n",
        "!pip install python-Levenshtein\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return wer\n",
        "\n",
        "# Example usage\n",
        "reference_text1 = \"the north wind and the sun were disputing which was the stronger\"\n",
        "hypothesis_text1 = \"the nurse wind and the sun world is building which was the stronger\"\n",
        "wer1 = calculate_wer(reference_text1, hypothesis_text1)\n",
        "print(f\"Word Error Rate (WER): {wer1}\")\n",
        "\n",
        "reference_text2 = \"the north wind and the sun were disputing which was the stronger\"\n",
        "hypothesis_text2 = \"the nursery and the sun world is putting which was Stronger\"\n",
        "wer2 = calculate_wer(reference_text2, hypothesis_text2)\n",
        "print(f\"Word Error Rate (WER): {wer2}\")\n",
        "\n",
        "reference_text3 = \"the north wind and the sun were disputing which was the stronger\"\n",
        "hypothesis_text3 = \"the nurse win and the song world is putting which was Stronger\"\n",
        "wer3 = calculate_wer(reference_text3, hypothesis_text3)\n",
        "print(f\"Word Error Rate (WER): {wer3}\")\n",
        "\n",
        "reference_text4 = \"the north wind and the sun were disputing which was the stronger\"\n",
        "hypothesis_text4 = \"the nurse wind and the sun world is putting this was the stronger\"\n",
        "wer4 = calculate_wer(reference_text4, hypothesis_text4)\n",
        "print(f\"Word Error Rate (WER): {wer4}\")\n",
        "\n",
        "reference_text5 = \"the north wind and the sun were disputing which was the stronger\"\n",
        "hypothesis_text5 = \"the nurse wind and the sun world is building which was the stronger\"\n",
        "wer5 = calculate_wer(reference_text5, hypothesis_text5)\n",
        "print(f\"Word Error Rate (WER): {wer5}\")\n",
        "\n",
        "reference_text6 = \"the north wind and the sun were disputing which was the stronger\"\n",
        "hypothesis_text6 = \"the nurse mean and the song world is putting which was the stronger\"\n",
        "wer6 = calculate_wer(reference_text6, hypothesis_text6)\n",
        "print(f\"Word Error Rate (WER): {wer6}\")\n",
        "\n",
        "reference_text7 = \"the north wind and the sun were disputing which was the stronger\"\n",
        "hypothesis_text7 = \"the nurse win and the sun was disputing which was the stronger\"\n",
        "wer7 = calculate_wer(reference_text7, hypothesis_text7)\n",
        "print(f\"Word Error Rate (WER): {wer7}\")\n",
        "\n",
        "reference_text8 = \"the north wind and the sun were disputing which was the stronger\"\n",
        "hypothesis_text8 = \"The North Wind and the sun world is building which was the stronger\"\n",
        "wer8 = calculate_wer(reference_text8, hypothesis_text8)\n",
        "print(f\"Word Error Rate (WER): {wer8}\")"
      ],
      "metadata": {
        "id": "NV60en-7KZTX",
        "outputId": "a72b5de9-a090-4358-8c59-bb8b4e14b893",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.10/dist-packages (0.21.1)\n",
            "Requirement already satisfied: Levenshtein==0.21.1 in /usr/local/lib/python3.10/dist-packages (from python-Levenshtein) (0.21.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein==0.21.1->python-Levenshtein) (3.1.1)\n",
            "Word Error Rate (WER): 0.3333333333333333\n",
            "Word Error Rate (WER): 0.5833333333333334\n",
            "Word Error Rate (WER): 0.6666666666666666\n",
            "Word Error Rate (WER): 0.4166666666666667\n",
            "Word Error Rate (WER): 0.3333333333333333\n",
            "Word Error Rate (WER): 0.5\n",
            "Word Error Rate (WER): 0.25\n",
            "Word Error Rate (WER): 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üêô **8. STT (subject1, rep1, subordinate clause, compressed)**\n",
        "###üê• **compressed sentence divided into subordinate clause**"
      ],
      "metadata": {
        "id": "uzhbakt0fPcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "\n",
        "import os\n",
        "import speech_recognition as sr\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "\n",
        "    return text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"/content/sample_data/subj1_compressed_subordinate\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")"
      ],
      "metadata": {
        "id": "PKaDfU0ifOPZ",
        "outputId": "90f672f3-8f86-4224-d598-708fee4f7731",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "File: compressed_PYI_1_2_1_subordinate.wav\n",
            "Text: bring a trailer came along work in a warm\n",
            "Word Count: 9\n",
            "\n",
            "File: compressed_PYI_1_3_1_subordinate.wav\n",
            "Text: when a traveler came around worked in the warm clock\n",
            "Word Count: 10\n",
            "\n",
            "File: compressed_PYI_1_5_1_subordinate.wav\n",
            "Text: when a traveler came or not in the room clock\n",
            "Word Count: 10\n",
            "\n",
            "File: compressed_PYI_1_1_1_subordinate.wav\n",
            "Text: Atlanta traveler came along work in a room clock\n",
            "Word Count: 9\n",
            "\n",
            "File: compressed_PYI_1_6_1_subordinate.wav\n",
            "Text: when a traveler came around in a warm clock\n",
            "Word Count: 9\n",
            "\n",
            "File: compressed_PYI_1_8_1_subordinate.wav\n",
            "Text: when a traveler came or not wrap in a warm\n",
            "Word Count: 10\n",
            "\n",
            "File: compressed_PYI_1_4_1_subordinate.wav\n",
            "Text: when a traveler came a little rough in the warm clock\n",
            "Word Count: 11\n",
            "\n",
            "File: compressed_PYI_1_7_1_subordinate.wav\n",
            "Text: when a traveler came along rough in the warm clothes\n",
            "Word Count: 10\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üêô **9. WER (subject1, rep1, subordinate clause, compressed)**"
      ],
      "metadata": {
        "id": "LdqCHcSjVpTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#subj1_sent_rep1_compressed_subordinate\n",
        "\n",
        "!pip install python-Levenshtein\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return wer\n",
        "\n",
        "# Example usage\n",
        "reference_text1 = \"when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text1 = \"Atlanta traveler came along work in a room clock\"\n",
        "wer1 = calculate_wer(reference_text1, hypothesis_text1)\n",
        "print(f\"Word Error Rate (WER): {wer1}\")\n",
        "\n",
        "reference_text2 = \"when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text2 = \"bring a trailer came along work in a warm\"\n",
        "wer2 = calculate_wer(reference_text2, hypothesis_text2)\n",
        "print(f\"Word Error Rate (WER): {wer2}\")\n",
        "\n",
        "reference_text3 = \"when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text3 = \"when a traveler came around worked in the warm clock\"\n",
        "wer3 = calculate_wer(reference_text3, hypothesis_text3)\n",
        "print(f\"Word Error Rate (WER): {wer3}\")\n",
        "\n",
        "reference_text4 = \"when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text4 = \"when a traveler came a little rough in the warm clock\"\n",
        "wer4 = calculate_wer(reference_text4, hypothesis_text4)\n",
        "print(f\"Word Error Rate (WER): {wer4}\")\n",
        "\n",
        "reference_text5 = \"when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text5 = \"when a traveler came or not in the room clock\"\n",
        "wer5 = calculate_wer(reference_text5, hypothesis_text5)\n",
        "print(f\"Word Error Rate (WER): {wer5}\")\n",
        "\n",
        "reference_text6 = \"when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text6 = \"when a traveler came around in a warm clock\"\n",
        "wer6 = calculate_wer(reference_text6, hypothesis_text6)\n",
        "print(f\"Word Error Rate (WER): {wer6}\")\n",
        "\n",
        "reference_text7 = \"when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text7 = \"when a traveler came along rough in the warm clothes\"\n",
        "wer7 = calculate_wer(reference_text7, hypothesis_text7)\n",
        "print(f\"Word Error Rate (WER): {wer7}\")\n",
        "\n",
        "reference_text8 = \"when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text8 = \"when a traveler came or not wrap in a warm\"\n",
        "wer8 = calculate_wer(reference_text8, hypothesis_text8)\n",
        "print(f\"Word Error Rate (WER): {wer8}\")"
      ],
      "metadata": {
        "id": "yRiiUoVNKVj9",
        "outputId": "985a1ffe-f196-4c4c-c1e5-a0aa60026b9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.10/dist-packages (0.21.1)\n",
            "Requirement already satisfied: Levenshtein==0.21.1 in /usr/local/lib/python3.10/dist-packages (from python-Levenshtein) (0.21.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein==0.21.1->python-Levenshtein) (3.1.1)\n",
            "Word Error Rate (WER): 0.5\n",
            "Word Error Rate (WER): 0.4\n",
            "Word Error Rate (WER): 0.4\n",
            "Word Error Rate (WER): 0.5\n",
            "Word Error Rate (WER): 0.5\n",
            "Word Error Rate (WER): 0.3\n",
            "Word Error Rate (WER): 0.3\n",
            "Word Error Rate (WER): 0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üêô **10. STT (subject1, rep1, last 4 words, compressed)**"
      ],
      "metadata": {
        "id": "AEwn4VHDWAGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#last 4 words (compressed)\n",
        "\n",
        "!pip install SpeechRecognition\n",
        "\n",
        "import os\n",
        "import speech_recognition as sr\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "\n",
        "    return text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"/content/sample_data/subj1_compressed_last4words\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")"
      ],
      "metadata": {
        "id": "ASE3Eyt6jaT0",
        "outputId": "0465b01c-eca7-4446-df44-d6aa924bec26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "File: compressed_PYI_1_1_1_last4words.wav\n",
            "Text: in alarm clock\n",
            "Word Count: 3\n",
            "\n",
            "File: compressed_PYI_1_3_1_last4words.wav\n",
            "Text: in the alarm clock\n",
            "Word Count: 4\n",
            "\n",
            "File: compressed_PYI_1_8_1_last4words.wav\n",
            "Text: in a war\n",
            "Word Count: 3\n",
            "\n",
            "File: compressed_PYI_1_7_1_last4words.wav\n",
            "Text: in the warm Club\n",
            "Word Count: 4\n",
            "\n",
            "File: compressed_PYI_1_5_1_last4words.wav\n",
            "Text: in a room\n",
            "Word Count: 3\n",
            "\n",
            "File: compressed_PYI_1_2_1_last4words.wav\n",
            "Text: enough alarm\n",
            "Word Count: 2\n",
            "\n",
            "File: compressed_PYI_1_4_1_last4words.wav\n",
            "Text: in the alarm clock\n",
            "Word Count: 4\n",
            "\n",
            "File: compressed_PYI_1_6_1_last4words.wav\n",
            "Text: in a warm Club\n",
            "Word Count: 4\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üêô **11. WER(subject1, rep1, last 4 words, compressed)**"
      ],
      "metadata": {
        "id": "NUU8aY4yWMlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#subj1_sent_rep1_compressed_last4words\n",
        "\n",
        "!pip install python-Levenshtein\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return wer\n",
        "\n",
        "# Example usage\n",
        "reference_text1 = \"in a warm cloak\"\n",
        "hypothesis_text1 = \"in alarm clock\"\n",
        "wer1 = calculate_wer(reference_text1, hypothesis_text1)\n",
        "print(f\"Word Error Rate (WER): {wer1}\")\n",
        "\n",
        "reference_text2 = \"in a warm cloak\"\n",
        "hypothesis_text2 = \"enough alarm\"\n",
        "wer2 = calculate_wer(reference_text2, hypothesis_text2)\n",
        "print(f\"Word Error Rate (WER): {wer2}\")\n",
        "\n",
        "reference_text3 = \"in a warm cloak\"\n",
        "hypothesis_text3 = \"in the alarm clock\"\n",
        "wer3 = calculate_wer(reference_text3, hypothesis_text3)\n",
        "print(f\"Word Error Rate (WER): {wer3}\")\n",
        "\n",
        "reference_text4 = \"in a warm cloak\"\n",
        "hypothesis_text4 = \"in the alarm clock\"\n",
        "wer4 = calculate_wer(reference_text4, hypothesis_text4)\n",
        "print(f\"Word Error Rate (WER): {wer4}\")\n",
        "\n",
        "reference_text5 = \"in a warm cloak\"\n",
        "hypothesis_text5 = \"in a room\"\n",
        "wer5 = calculate_wer(reference_text5, hypothesis_text5)\n",
        "print(f\"Word Error Rate (WER): {wer5}\")\n",
        "\n",
        "reference_text6 = \"in a warm cloak\"\n",
        "hypothesis_text6 = \"in a warm Club\"\n",
        "wer6 = calculate_wer(reference_text6, hypothesis_text6)\n",
        "print(f\"Word Error Rate (WER): {wer6}\")\n",
        "\n",
        "reference_text7 = \"in a warm cloak\"\n",
        "hypothesis_text7 = \"in the warm Club\"\n",
        "wer7 = calculate_wer(reference_text7, hypothesis_text7)\n",
        "print(f\"Word Error Rate (WER): {wer7}\")\n",
        "\n",
        "reference_text8 = \"in a warm cloak\"\n",
        "hypothesis_text8 = \"in a war\"\n",
        "wer8 = calculate_wer(reference_text8, hypothesis_text8)\n",
        "print(f\"Word Error Rate (WER): {wer8}\")"
      ],
      "metadata": {
        "id": "6aMIDjNUH_ZS",
        "outputId": "3a26be2c-a280-47ec-a348-706dbc800191",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.10/dist-packages (0.21.1)\n",
            "Requirement already satisfied: Levenshtein==0.21.1 in /usr/local/lib/python3.10/dist-packages (from python-Levenshtein) (0.21.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein==0.21.1->python-Levenshtein) (3.1.1)\n",
            "Word Error Rate (WER): 0.75\n",
            "Word Error Rate (WER): 1.0\n",
            "Word Error Rate (WER): 0.75\n",
            "Word Error Rate (WER): 0.75\n",
            "Word Error Rate (WER): 0.5\n",
            "Word Error Rate (WER): 0.25\n",
            "Word Error Rate (WER): 0.5\n",
            "Word Error Rate (WER): 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚ùé**Ignore below!**\n",
        "\n",
        "Word Error Rate\n",
        "\n",
        "Use small letters"
      ],
      "metadata": {
        "id": "GlUCzpTnGgsC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZU4a35-Gvns",
        "outputId": "472ad12d-8803-4e7a-af16-b5897ade0852"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the': 10, 'nurse': 2, 'wind': 2, 'and': 3, 'sun': 1, 'world': 1, 'is': 1, 'building': 1, 'which': 1, 'was': 2, 'stronger': 2, 'when': 1, 'a': 2, 'traveler': 2, 'came': 1, 'along': 1, 'work': 1, 'in': 2, 'warm': 1, 'clock': 2, 'they': 1, 'are': 1, 'reset': 1, 'one': 1, 'who': 1, 'first': 1, 'succeeded': 1, 'making': 1, 'take': 1, 'his': 2, 'of': 1, 'should': 1, 'be': 1, 'considered': 1, 'than': 2, 'other': 1, 'blew': 2, 'as': 2, 'hard': 1, 'he': 2, 'could': 1, 'but': 1, 'more': 2, 'closely': 1, 'The': 1, 'Traveler': 1, 'from': 1, 'Club': 1, 'around': 1, 'him': 1, 'I': 1, 'lost': 1, 'nursery': 1, 'immediately': 1, 'go': 1, 'traveling': 1, 'only': 1}\n"
          ]
        }
      ],
      "source": [
        "def word_count(text):\n",
        "    # Split the text into words\n",
        "    words = text.split()\n",
        "\n",
        "    # Create a dictionary to store word counts\n",
        "    word_counts = {}\n",
        "\n",
        "    # Count the occurrences of each word\n",
        "    for word in words:\n",
        "        if word in word_counts:\n",
        "            word_counts[word] += 1\n",
        "        else:\n",
        "            word_counts[word] = 1\n",
        "\n",
        "    return word_counts\n",
        "\n",
        "\n",
        "subj1_rep1_ori = \"the nurse wind and the sun world is building which was the stronger when a traveler came along work in a warm clock they are reset the one who first succeeded in making the traveler take his clock of should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely The Traveler from his Club around him and I lost the nursery and immediately go traveling was only\"\n",
        "counts = word_count(subj1_rep1_ori)\n",
        "print(counts)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "\n",
        "subj1_rep1_ori = \"the nurse wind and the sun world is building which was the stronger when a traveler came along work in a warm clock they are reset the one who first succeeded in making the traveler take his clock of should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely The Traveler from his Club around him and I lost the nursery and immediately go traveling was only\"\n",
        "wc1 = count_words(subj1_rep1_ori)\n",
        "print(wc1)\n",
        "\n",
        "subj1_rep1_compress = \"the nurse wind and the sun world is building which was the stronger when a traveler came along work in a warm clock they are reset the one who first succeeded in making the traveler take his clock of should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the\"\n",
        "wc1_1 = count_words(subj1_rep1_compress)\n",
        "print(wc1_1)\n",
        "print('\\n')\n",
        "\n",
        "subj1_rep2_ori = \"the nursery and the sun world is putting which was Stronger when I travel I came along work in a warm Club they are really that the one who forced to succeed in making the traveler take his clock of should be considered stronger than the other in the nurse main blue as hard as he could put them away he blew the more closely did The Traveler for his Club around him and I lost the nursery nursery\"\n",
        "wc2 = count_words(subj1_rep2_ori)\n",
        "print(wc2)\n",
        "\n",
        "subj1_rep2_compress = \"the nursery and the sun world is putting which was Stronger when I travel I came along work in a warm Club they are really that the one who forced to succeed in making the traveler take his clock of should be considered stronger than the other in the nurse main blue as hard as he could put them away he blew the more closely did The Traveler for his Club around him and I lost the nursery nursery\"\n",
        "wc2_1 = count_words(subj1_rep2_compress)\n",
        "print(wc2_1)\n",
        "print('\\n')\n",
        "\n",
        "subj1_rep3_ori = \"the nurse win and the song world is putting which was Stronger when a traveler came around worked in the alarm clock they are really that the one who first succeed in making the traveler take his clothes off should be considered stronger than the other then the nurse wind blew as hard as he could but\"\n",
        "wc3 = count_words(subj1_rep3_ori)\n",
        "print(wc3)\n",
        "\n",
        "subj1_rep3_compress = \"the nurse win and the song world is putting which was Stronger when a traveler came around worked in the alarm clock they are really that the one who first succeed in making the traveler take his clothes off should be considered stronger than the other then the nurse wind blew as hard as he could but\"\n",
        "wc3_1 = count_words(subj1_rep3_compress)\n",
        "print(wc3_1)\n",
        "print('\\n')\n",
        "\n",
        "subj1_rep4_ori = \"the nurse wind and the sun world is putting this was the stronger when a traveler came along with the warm clock they are read that the one who first succeeded in making the traveler take his clock off should be considered a stronger than the other than the north wind blow us hard as he could put the more he blew the more closely did The Traveler for his clock around him and unless the north wind gave up the tent in the song in the sky shine on me and immediately was alive to confess that the sun was the stronger of\"\n",
        "wc4 = count_words(subj1_rep4_ori)\n",
        "print(wc4)\n",
        "\n",
        "subj1_rep4_compress = \"the nurse wind and the sun world is putting this was the stronger when a traveler came out of work in the warm clock they are read that\"\n",
        "wc4_1 = count_words(subj1_rep4_compress)\n",
        "print(wc4_1)\n",
        "print('\\n')\n",
        "\n",
        "subj1_rep5_ori = \"the nurse win and the song where they speak English with the stronger when the traveler came or not in the room clock they agreed that the one who first succeed in making the traveler take his clock off should be considered stronger than the other than the north wind blew as hard as he could put the more\"\n",
        "wc5 = count_words(subj1_rep5_ori)\n",
        "print(wc5)\n",
        "\n",
        "subj1_rep5_compress = \"the nurse win and the song where they speak English with the stronger when the traveler came or not in the room clock they agreed that the one who first succeed in making the traveler take his clock off should be considered stronger than the other than the north wind blew as hard as he could put the more he blew the more closely did the turbo for his Club around him and I left the list the nursery\"\n",
        "wc5_1 = count_words(subj1_rep5_compress)\n",
        "print(wc5_1)\n",
        "print('\\n')\n",
        "\n",
        "subj1_rep6_ori = \"the nurse mean and the song world is putting which was the stronger when a traveler came along rough in a warm clock they agreed that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could the more he blew the more closely together for his clock around him and I left the nursery was obviously to confess that the song was the stronger of the two\"\n",
        "wc6 = count_words(subj1_rep6_ori)\n",
        "print(wc6)\n",
        "\n",
        "subj1_rep6_compress = \"the nurse mean and the song world is putting which was the stronger when a traveler came along rough in a warm clock they agreed that the one who first succeeded in\"\n",
        "wc6_1 = count_words(subj1_rep6_compress)\n",
        "print(wc6_1)\n",
        "print('\\n')\n",
        "\n",
        "subj1_rep7_ori = \"the nurse win and the sun was disputing which was the stronger when a traveler came along Route in the warm clothes they are great that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely the doctor for his clock around him and I left and there's one game of the attempt in the Sun in the sky shine at warmly and immediately to travel to the nurse when was over to confess that the sun was the stronger of the two\"\n",
        "wc7 = count_words(subj1_rep7_ori)\n",
        "print(wc7)\n",
        "\n",
        "subj1_rep7_compress = \"the nurse win and the sun was disputing which was the stronger when a traveler came along Route in the warm clothes they are great that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely the doctor for his clock around him and I left and there's one game of the attempt in the Sun in the sky shine at warmly and\"\n",
        "wc7_1 = count_words(subj1_rep7_compress)\n",
        "print(wc7_1)\n",
        "print('\\n')\n",
        "\n",
        "subj1_rep8_ori = \"the nurse win and the sun was disputing which was the stronger when a traveler came along Route in the warm clothes they are great that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely the doctor for his clock around him and I left and there's one game of the attempt in the Sun in the sky shine at warmly and immediately to travel to the nurse when was over to confess that the sun was the stronger of the two\"\n",
        "wc8 = count_words(subj1_rep8_ori)\n",
        "print(wc8)\n",
        "\n",
        "subj1_rep8_compress = \"the nurse win and the sun was disputing which was the stronger when a traveler came along Route in the warm clothes they are great that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the\"\n",
        "wc8_1 = count_words(subj1_rep8_compress)\n",
        "print(wc8_1)\n",
        "print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfxUl393Js2S",
        "outputId": "808c059b-0b1f-4bf5-ba16-dd684853a51e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "82\n",
            "62\n",
            "\n",
            "\n",
            "79\n",
            "79\n",
            "\n",
            "\n",
            "57\n",
            "57\n",
            "\n",
            "\n",
            "104\n",
            "28\n",
            "\n",
            "\n",
            "59\n",
            "79\n",
            "\n",
            "\n",
            "87\n",
            "32\n",
            "\n",
            "\n",
            "111\n",
            "91\n",
            "\n",
            "\n",
            "111\n",
            "62\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}