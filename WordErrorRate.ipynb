{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3pfWt4LbZ86kW5Qe8MmJ9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ms624atyale/CL4Research/blob/main/WordErrorRate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To convert human speech in wave format to text using Automatic Speech Recognition (ASR) or Speech-to-Text (STT) technology, you can utilize the SpeechRecognition library in Python. This library provides an interface to several popular STT engines. Here's an example code snippet:\n",
        "\n",
        "In this example, the convert_speech_to_text() function takes the path to the WAV audio file as input and returns the recognized text. It uses the speech_recognition library to create a Recognizer instance. The audio file is loaded using sr.AudioFile, and the record() method is used to extract the audio data.\n",
        "\n",
        "The recognize_google() method is used with the Google Speech Recognition API to perform the speech-to-text conversion. This requires an internet connection and may be subject to usage limits and terms of service.\n",
        "\n",
        "Replace \"path/to/your/audio.wav\" with the actual path to your WAV audio file. After running the code, the recognized text will be printed to the console.\n",
        "\n",
        "Note that the accuracy of speech recognition can vary depending on factors such as audio quality, background noise, speaker accent, and the specific STT engine being used."
      ],
      "metadata": {
        "id": "a06kFjdPFdTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "import speech_recognition as sr\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "\n",
        "    return text\n",
        "\n",
        "# Example usage\n",
        "audio_file = \"/content/sample_data/Dataset4STT/EnglishAccentedES_MSon_sample.wav\"\n",
        "converted_text = convert_speech_to_text(audio_file)\n",
        "print(converted_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ApNNo5NFdy6",
        "outputId": "7569b1ba-4e5d-4211-c4cc-3f3498bd949f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.10.0-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "Installing collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.10.0\n",
            "hi my name is Emma Thompson\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "import speech_recognition as sr\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "\n",
        "    return text\n",
        "\n",
        "# Example usage\n",
        "audio_file = \"/content/sample_data/Dataset4STT/KoreanAccentedES_MSon_sample2.wav\"\n",
        "converted_text = convert_speech_to_text(audio_file)\n",
        "print(converted_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-H84VodVHs3n",
        "outputId": "700e125d-82ef-483d-d915-c7511b3cf405"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "is this real\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, the calculate_wer() function takes two input parameters: the reference text (the ground truth) and the hypothesis text (the recognized text generated by the STT system). It calculates the Levenshtein distance between the two texts and then divides it by the length of the reference text to obtain the Word Error Rate (WER). The WER represents the percentage of words that were incorrectly recognized or transcribed.\n",
        "\n",
        "You can replace the reference_text and hypothesis_text variables with your own strings or integrate this code with your STT system to compare the recognized text against the ground truth.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Regenerate response"
      ],
      "metadata": {
        "id": "KuzutE4HBGG6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To convert multiple WAV files in the same folder to text using Speech-to-Text (STT), you can modify the previous code to iterate over the files in the folder and process them one by one. Here's an example code snippet:\n",
        "\n",
        "In this example, the code iterates over the files in the specified folder using os.listdir(). It checks if each file has the \".wav\" extension and constructs the full path to the audio file using os.path.join(). The convert_speech_to_text() function is then called for each WAV file to convert it to text using STT.\n",
        "\n",
        "The converted text is printed to the console along with the corresponding file name. You can customize the output format or save the results to a file as per your requirement.\n",
        "\n",
        "Make sure to replace \"path/to/your/folder\" with the actual path to the folder containing the WAV files. Note that this code assumes all the WAV files in the folder can be successfully processed by the STT engine."
      ],
      "metadata": {
        "id": "LU7QCXQKJCbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import speech_recognition as sr\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "\n",
        "    return text\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"/content/sample_data/Dataset4STT\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "        converted_text = convert_speech_to_text(audio_file)\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMM9tWYmJDYI",
        "outputId": "fdded4ec-58ea-4d56-e29e-41d1809da207"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File: KoreanAccentedES_MSon_sample2.wav\n",
            "Text: is this real\n",
            "\n",
            "File: KoreanAccentedES_MSon_sample.wav\n",
            "Text: hi my name is Emma Thompson\n",
            "\n",
            "File: EnglishAccentedES_MSon_sample.wav\n",
            "Text: hi my name is Emma Thompson\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAi65SYgBCfA",
        "outputId": "2edfebec-c32c-4b95-ecb5-4044fefae4cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python_Levenshtein-0.21.1-py3-none-any.whl (9.4 kB)\n",
            "Collecting Levenshtein==0.21.1 (from python-Levenshtein)\n",
            "  Downloading Levenshtein-0.21.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=2.3.0 (from Levenshtein==0.21.1->python-Levenshtein)\n",
            "  Downloading rapidfuzz-3.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.21.1 python-Levenshtein-0.21.1 rapidfuzz-3.1.1\n",
            "Word Error Rate (WER): 0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install python-Levenshtein\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return wer\n",
        "\n",
        "# Example usage\n",
        "reference_text = \"This is the reference text\"\n",
        "hypothesis_text = \"This is the hypothesis text\"\n",
        "\n",
        "wer = calculate_wer(reference_text, hypothesis_text)\n",
        "print(f\"Word Error Rate (WER): {wer}\")\n"
      ]
    }
  ]
}