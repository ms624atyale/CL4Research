{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxtZYYBgh1GrNPzFYbOsEi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ms624atyale/CL4Research/blob/main/2_Speech2Text_WordCount_WordErrorRate_Original_Compressed_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this modified code, the convert_speech_to_text() function remains the same as before, which converts speech to text using Google STT. The count_words() function also remains the same, which counts the number of words in the text.\n",
        "\n",
        "The code iterates over the WAV files in the specified folder. For each WAV file, it converts the speech to text using convert_speech_to_text(), then counts the number of words in the converted text using count_words(). Finally, it prints the filename, converted text, and word count for each WAV file.\n",
        "\n",
        "Make sure to adjust the folder_path variable to the actual path of your WAV files. After making these adjustments, run the code, and it will apply Google STT on each WAV file, retrieve the converted text, and count the number of words in the text for each WAV file."
      ],
      "metadata": {
        "id": "qQVtTYE72IgK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üêπ <font color = 'brown'> google STT (SpeechRecognition package) applied to a list of oritinal wav. files and their corresponding word count** ‚§µÔ∏è\n",
        "\n",
        "###**üåµ 1. STT (subj1, rep1, all text, original)**"
      ],
      "metadata": {
        "id": "fXvHSq8o74HD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "\n",
        "import os\n",
        "import speech_recognition as sr\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "\n",
        "    return text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"/content/sample_data/subj1_para_8original\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKdLXKnv2E55",
        "outputId": "08735f9a-4437-426e-ea77-0f57c1f9794b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "File: subj1_session1_rep7.wav\n",
            "Text: the nurse win and the sun was disputing which was the stronger when a traveler came along Route in the warm clothes they are great that the one who first succeeded in\n",
            "Word Count: 32\n",
            "\n",
            "File: subj1_session1_rep6.wav\n",
            "Text: the nurse mean and the song world is putting which was the stronger when a traveler came along rough in a warm clock they agreed that the one who first succeeded in\n",
            "Word Count: 32\n",
            "\n",
            "File: subj1_session1_rep3.wav\n",
            "Text: the nurse win and the song world is putting which was Stronger when a traveler came around worked in the alarm clock they are really that the one who first succeed in making the traveler take his clothes off should be considered stronger than the other then the nurse wind blew as hard as he could but\n",
            "Word Count: 57\n",
            "\n",
            "File: subj1_session1_rep8.wav\n",
            "Text: the nurse win and the sun was disputing which was the stronger when a traveler came along Route in the warm clothes they are great that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely the doctor for his clock around him and I left and there's one game of the attempt in the Sun in the sky shine at warmly and immediately to travel to the nurse when was over to confess that the sun was the stronger of the two\n",
            "Word Count: 111\n",
            "\n",
            "File: subj1_session1_rep4.wav\n",
            "Text: the nurse wind and the sun world is putting this was the stronger when a traveler came along with the warm clock they are read that the one who first succeeded in making the traveler take his clock off should be considered a stronger than the other than the north wind blow us hard as he could put the more he blew the more closely did The Traveler for his clock around him and unless the north wind gave up the tent in the song in the sky shine on me and immediately was alive to confess that the sun was the stronger of\n",
            "Word Count: 104\n",
            "\n",
            "File: subj1_session1_rep1.wav\n",
            "Text: the nurse wind and the sun world is building which was the stronger when a traveler came along work in a warm clock they are reset the one who first succeeded in making the traveler take his clock of should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely The Traveler from his Club around him and I lost the nursery and immediately go traveling was only\n",
            "Word Count: 82\n",
            "\n",
            "File: subj1_session1_rep5.wav\n",
            "Text: the nurse win and the song where they speak English with the stronger when the traveler came or not in the room clock they agreed that the one who first succeed in making the traveler take his clock off should be considered stronger than the other than the north wind blew as hard as he could put the more he blew the more closely did the turbo for his Club around him and I left the list the nursery was over to confess that the song was the stronger of the two\n",
            "Word Count: 92\n",
            "\n",
            "File: subj1_session1_rep2.wav\n",
            "Text: the nursery and the sun world is putting which was Stronger when I travel I came along work in a warm Club they are really that the one who forced to succeed in making the traveler take his clock of should be considered stronger than the other in the nurse main blue as hard as he could put them away he blew the more closely did The Traveler for his Club around him and I lost the nursery nursery\n",
            "Word Count: 79\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üåµ 2. WER (subj1, rep1, all text, original)**"
      ],
      "metadata": {
        "id": "jKK1eYa1ZIRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Original Full Text of 'The North Wind and the Sun' abbreviated as OFT\n",
        "!pip install python-Levenshtein\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return wer\n",
        "\n",
        "# Example usage\n",
        "reference_text1 = \"\"\n",
        "hypothesis_text1 = \"\"\n",
        "OFT_wer1 = calculate_wer(reference_text1, hypothesis_text1)\n",
        "print(f\"Word Error Rate (WER): {OFT_wer1}\")\n",
        "\n",
        "reference_text2 = \"\"\n",
        "hypothesis_text2 = \"\"\n",
        "OFT_wer2 = calculate_wer(reference_text2, hypothesis_text2)\n",
        "print(f\"Word Error Rate (WER): {OFT_wer2}\")\n",
        "\n",
        "reference_text3 = \"\"\n",
        "hypothesis_text3 = \"\"\n",
        "OFT_OFT_wer3 = calculate_wer(reference_text3, hypothesis_text3)\n",
        "print(f\"Word Error Rate (WER): {OFT_wer3}\")\n",
        "\n",
        "reference_text4 = \"\"\n",
        "hypothesis_text4 = \"\"\n",
        "OFT_wer4 = calculate_wer(reference_text4, hypothesis_text4)\n",
        "print(f\"Word Error Rate (WER): {OFT_wer4}\")\n",
        "\n",
        "reference_text5 = \"\"\n",
        "hypothesis_text5 = \"\"\n",
        "OFT_wer5 = calculate_wer(reference_text5, hypothesis_text5)\n",
        "print(f\"Word Error Rate (WER): {OFT_wer5}\")\n",
        "\n",
        "reference_text6 = \"\"\n",
        "hypothesis_text6 = \"\"\n",
        "OFT_wer6 = calculate_wer(reference_text6, hypothesis_text6)\n",
        "print(f\"Word Error Rate (WER): {OFT_wer6}\")\n",
        "\n",
        "reference_text7 = \"\"\n",
        "hypothesis_text7 = \"\"\n",
        "OFT_wer7 = calculate_wer(reference_text7, hypothesis_text7)\n",
        "print(f\"Word Error Rate (WER): {OFT_wer7}\")\n",
        "\n",
        "reference_text8 = \"\"\n",
        "hypothesis_text8 = \"\"\n",
        "OFT_wer8 = calculate_wer(reference_text8, hypothesis_text8)\n",
        "print(f\"Word Error Rate (WER): {OFT_wer8}\")"
      ],
      "metadata": {
        "id": "Mg470zPla7-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üåµ  3. STT (subj1, rep1, sentence1, original)**"
      ],
      "metadata": {
        "id": "TGzZW3DS8aw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "\n",
        "import os\n",
        "import speech_recognition as sr\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "\n",
        "    return text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"/content/sample_data/subj1_sent_8original\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bxfabYsAEwk",
        "outputId": "e2c5f49c-12ef-4937-f1d5-0ac992da6381"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "File: PYI_1_4_1.wav\n",
            "Text: the nurse wind and the sun world is putting this was the stronger when a Traveller came out of work in the warm clock\n",
            "Word Count: 24\n",
            "\n",
            "File: PYI_1_8_1.wav\n",
            "Text: The North Wind and the sun world is building which was the stronger when a traveler came or not in a warm\n",
            "Word Count: 22\n",
            "\n",
            "File: PYI_1_1_1.wav\n",
            "Text: the nurse wind and the sun world is building which was the stronger when a traveler came along work in a warm clock\n",
            "Word Count: 23\n",
            "\n",
            "File: PYI_1_7_1.wav\n",
            "Text: the nurse win and the sun was disputing which was the stronger when a traveler came along Route in the warm clothes\n",
            "Word Count: 22\n",
            "\n",
            "File: PYI_1_3_1.wav\n",
            "Text: the nurse win and the song world is putting which was Stronger when a traveler came around worked in the alarm clock\n",
            "Word Count: 22\n",
            "\n",
            "File: PYI_1_5_1.wav\n",
            "Text: the nurse win and the song where they speak English with the stronger when the traveler came or not in the wrong\n",
            "Word Count: 22\n",
            "\n",
            "File: PYI_1_2_1.wav\n",
            "Text: the nursery and the sun world is putting which was Stronger when I travel I came along work in a warm\n",
            "Word Count: 21\n",
            "\n",
            "File: PYI_1_6_1.wav\n",
            "Text: the nurse mean and the song world is putting which was the stronger when a traveler came along rough in a warm clock\n",
            "Word Count: 23\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üåµ  4 WER (subj1, rep1, sentence1, original)**"
      ],
      "metadata": {
        "id": "-vauZFNEZVDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Temp\n",
        "\n",
        "!pip install python-Levenshtein\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return wer\n",
        "\n",
        "# Example usage\n",
        "reference_text1 = \"\"\n",
        "hypothesis_text1 = \"\"\n",
        "wer1 = calculate_wer(reference_text1, hypothesis_text1)\n",
        "print(f\"Word Error Rate (WER): {wer1}\")\n",
        "\n",
        "reference_text2 = \"\"\n",
        "hypothesis_text2 = \"\"\n",
        "wer2 = calculate_wer(reference_text2, hypothesis_text2)\n",
        "print(f\"Word Error Rate (WER): {wer2}\")\n",
        "\n",
        "reference_text3 = \"\"\n",
        "hypothesis_text3 = \"\"\n",
        "wer3 = calculate_wer(reference_text3, hypothesis_text3)\n",
        "print(f\"Word Error Rate (WER): {wer3}\")\n",
        "\n",
        "reference_text4 = \"\"\n",
        "hypothesis_text4 = \"\"\n",
        "wer4 = calculate_wer(reference_text4, hypothesis_text4)\n",
        "print(f\"Word Error Rate (WER): {wer4}\")\n",
        "\n",
        "reference_text5 = \"\"\n",
        "hypothesis_text5 = \"\"\n",
        "wer5 = calculate_wer(reference_text5, hypothesis_text5)\n",
        "print(f\"Word Error Rate (WER): {wer5}\")\n",
        "\n",
        "reference_text6 = \"\"\n",
        "hypothesis_text6 = \"\"\n",
        "wer6 = calculate_wer(reference_text6, hypothesis_text6)\n",
        "print(f\"Word Error Rate (WER): {wer6}\")\n",
        "\n",
        "reference_text7 = \"\"\n",
        "hypothesis_text7 = \"\"\n",
        "wer7 = calculate_wer(reference_text7, hypothesis_text7)\n",
        "print(f\"Word Error Rate (WER): {wer7}\")\n",
        "\n",
        "reference_text8 = \"\"\n",
        "hypothesis_text8 = \"\"\n",
        "wer8 = calculate_wer(reference_text8, hypothesis_text8)\n",
        "print(f\"Word Error Rate (WER): {wer8}\")"
      ],
      "metadata": {
        "id": "dfaro8QIaB0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üåµ  5. STT (subj1, rep1, main clause, original)**\n",
        "###üê• **original sentence divided into main clause**"
      ],
      "metadata": {
        "id": "wBChSHExcWf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "\n",
        "import os\n",
        "import speech_recognition as sr\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "\n",
        "    return text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"/content/sample_data/subj1_original_main\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")"
      ],
      "metadata": {
        "id": "4YCPK_9YcdkQ",
        "outputId": "d4c7e2de-dd0d-478f-92c9-a1615a4ac4cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.10.0-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "Installing collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.10.0\n",
            "File: PYI_1_6_1_main.wav\n",
            "Text: the nurse mean and the song world is putting which was the stronger\n",
            "Word Count: 13\n",
            "\n",
            "File: PYI_1_4_1_main.wav\n",
            "Text: the nurse wind and the sun world is putting this was the stronger\n",
            "Word Count: 13\n",
            "\n",
            "File: PYI_1_1_1_main.wav\n",
            "Text: the nurse wind and the sun world is building which was the stronger\n",
            "Word Count: 13\n",
            "\n",
            "File: PYI_1_3_1_main.wav\n",
            "Text: the nurse win and the song world is putting which was Stronger\n",
            "Word Count: 12\n",
            "\n",
            "File: PYI_1_8_1_main.wav\n",
            "Text: The North Wind and the sun world is building which was the stronger\n",
            "Word Count: 13\n",
            "\n",
            "File: PYI_1_2_1_main.wav\n",
            "Text: the nursery and the sun world is putting which was Stronger\n",
            "Word Count: 11\n",
            "\n",
            "File: PYI_1_7_1_main.wav\n",
            "Text: the nurse win and the sun was disputing which was the stronger\n",
            "Word Count: 12\n",
            "\n",
            "File: PYI_1_5_1_main.wav\n",
            "Text: the nurse wind and the sun world is building which was the stronger\n",
            "Word Count: 13\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üåµ  6. WER (subj1, rep1, main clause, original)**"
      ],
      "metadata": {
        "id": "WLdGxED_aGs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#subj1_sent_rep1_original_main\n",
        "\n",
        "!pip install python-Levenshtein\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return wer\n",
        "\n",
        "# Example usage\n",
        "reference_text1 = \"the north wind and the sun were disputing which was the stronger\"\n",
        "hypothesis_text1 = \"the nurse wind and the sun world is building which was the stronger\"\n",
        "wer1 = calculate_wer(reference_text1, hypothesis_text1)\n",
        "print(f\"Word Error Rate (WER): {wer1}\")\n",
        "\n",
        "reference_text2 = \"the north wind and the sun were disputing which was the stronger\"\n",
        "hypothesis_text2 = \"the nursery and the sun world is putting which was Stronger\"\n",
        "wer2 = calculate_wer(reference_text2, hypothesis_text2)\n",
        "print(f\"Word Error Rate (WER): {wer2}\")\n",
        "\n",
        "reference_text3 = \"the north wind and the sun were disputing which was the stronger\"\n",
        "hypothesis_text3 = \"the nurse win and the song world is putting which was Stronger\"\n",
        "wer3 = calculate_wer(reference_text3, hypothesis_text3)\n",
        "print(f\"Word Error Rate (WER): {wer3}\")\n",
        "\n",
        "reference_text4 = \"the north wind and the sun were disputing which was the stronger\"\n",
        "hypothesis_text4 = \"the nurse wind and the sun world is putting this was the stronger\"\n",
        "wer4 = calculate_wer(reference_text4, hypothesis_text4)\n",
        "print(f\"Word Error Rate (WER): {wer4}\")\n",
        "\n",
        "reference_text5 = \"the north wind and the sun were disputing which was the stronger\"\n",
        "hypothesis_text5 = \"the nurse wind and the sun world is building which was the stronger\"\n",
        "wer5 = calculate_wer(reference_text5, hypothesis_text5)\n",
        "print(f\"Word Error Rate (WER): {wer5}\")\n",
        "\n",
        "reference_text6 = \"the north wind and the sun were disputing which was the stronger\"\n",
        "hypothesis_text6 = \"the nurse mean and the song world is putting which was the stronger\"\n",
        "wer6 = calculate_wer(reference_text6, hypothesis_text6)\n",
        "print(f\"Word Error Rate (WER): {wer6}\")\n",
        "\n",
        "reference_text7 = \"the north wind and the sun were disputing which was the stronger\"\n",
        "hypothesis_text7 = \"the nurse win and the sun was disputing which was the stronger\"\n",
        "wer7 = calculate_wer(reference_text7, hypothesis_text7)\n",
        "print(f\"Word Error Rate (WER): {wer7}\")\n",
        "\n",
        "reference_text8 = \"the north wind and the sun were disputing which was the stronger\"\n",
        "hypothesis_text8 = \"The North Wind and the sun world is building which was the stronger\"\n",
        "wer8 = calculate_wer(reference_text8, hypothesis_text8)\n",
        "print(f\"Word Error Rate (WER): {wer8}\")"
      ],
      "metadata": {
        "id": "T3zyL_ebLMmn",
        "outputId": "0493dd7c-dbc3-453d-ffe4-a19df8a16482",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.10/dist-packages (0.21.1)\n",
            "Requirement already satisfied: Levenshtein==0.21.1 in /usr/local/lib/python3.10/dist-packages (from python-Levenshtein) (0.21.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein==0.21.1->python-Levenshtein) (3.1.1)\n",
            "Word Error Rate (WER): 0.3333333333333333\n",
            "Word Error Rate (WER): 0.5833333333333334\n",
            "Word Error Rate (WER): 0.6666666666666666\n",
            "Word Error Rate (WER): 0.4166666666666667\n",
            "Word Error Rate (WER): 0.3333333333333333\n",
            "Word Error Rate (WER): 0.5\n",
            "Word Error Rate (WER): 0.25\n",
            "Word Error Rate (WER): 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üåµ  7. STT (subj1, rep1, subordinate clause, original)**\n",
        "###üê• **original sentence divided into subordinate clause**"
      ],
      "metadata": {
        "id": "aRdTVoFIdrN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "\n",
        "import os\n",
        "import speech_recognition as sr\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "\n",
        "    return text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"/content/sample_data/subj1_original_subordinate\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")"
      ],
      "metadata": {
        "id": "qqWhaWHfdoqd",
        "outputId": "9dc0c901-eb57-450f-ef9f-bf79aa67ccd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "File: PYI_1_7_1_subordinate.wav\n",
            "Text: when a traveler came along rough in the warm clothes\n",
            "Word Count: 10\n",
            "\n",
            "File: PYI_1_1_1_subordinate.wav\n",
            "Text: Atlanta traveler came along work in a warm clock\n",
            "Word Count: 9\n",
            "\n",
            "File: PYI_1_8_1_subordinate.wav\n",
            "Text: when a traveler came or not wrap in a warm\n",
            "Word Count: 10\n",
            "\n",
            "File: PYI_1_4_1_subordinate.wav\n",
            "Text: when a Traveller came out of work in the warm clock\n",
            "Word Count: 11\n",
            "\n",
            "File: PYI_1_6_1_subordinate.wav\n",
            "Text: when a traveler came along rough in a warm clock\n",
            "Word Count: 10\n",
            "\n",
            "File: PYI_1_5_1_subordinate.wav\n",
            "Text: when the traveler came or not in a room clock\n",
            "Word Count: 10\n",
            "\n",
            "File: PYI_1_2_1_subordinate.wav\n",
            "Text: when a turtle that came along with in a warm\n",
            "Word Count: 10\n",
            "\n",
            "File: PYI_1_3_1_subordinate.wav\n",
            "Text: when a traveler came around worked in the alarm clock\n",
            "Word Count: 10\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üåµ  8. WER (subj1, rep1, subordinate clause, original)**"
      ],
      "metadata": {
        "id": "pj5h1HY9aQnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#subj1_sent_rep1_original_subordinate\n",
        "\n",
        "!pip install python-Levenshtein\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return wer\n",
        "\n",
        "# Example usage\n",
        "reference_text1 = \"when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text1 = \"Atlanta traveler came along work in a warm clock\"\n",
        "wer1 = calculate_wer(reference_text1, hypothesis_text1)\n",
        "print(f\"Word Error Rate (WER): {wer1}\")\n",
        "\n",
        "reference_text2 = \"when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text2 = \"when a turtle that came along with in a warm\"\n",
        "wer2 = calculate_wer(reference_text2, hypothesis_text2)\n",
        "print(f\"Word Error Rate (WER): {wer2}\")\n",
        "\n",
        "reference_text3 = \"when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text3 = \"when a traveler came around worked in the alarm clock\"\n",
        "wer3 = calculate_wer(reference_text3, hypothesis_text3)\n",
        "print(f\"Word Error Rate (WER): {wer3}\")\n",
        "\n",
        "reference_text4 = \"when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text4 = \"when a Traveller came out of work in the warm clock\"\n",
        "wer4 = calculate_wer(reference_text4, hypothesis_text4)\n",
        "print(f\"Word Error Rate (WER): {wer4}\")\n",
        "\n",
        "reference_text5 = \"when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text5 = \"when the traveler came or not in a room clock\"\n",
        "wer5 = calculate_wer(reference_text5, hypothesis_text5)\n",
        "print(f\"Word Error Rate (WER): {wer5}\")\n",
        "\n",
        "reference_text6 = \"when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text6 = \"when a traveler came along rough in a warm clock\"\n",
        "wer6 = calculate_wer(reference_text6, hypothesis_text6)\n",
        "print(f\"Word Error Rate (WER): {wer6}\")\n",
        "\n",
        "reference_text7 = \"when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text7 = \"when a traveler came along rough in the warm clothes\"\n",
        "wer7 = calculate_wer(reference_text7, hypothesis_text7)\n",
        "print(f\"Word Error Rate (WER): {wer7}\")\n",
        "\n",
        "reference_text8 = \"when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text8 = \"when a traveler came or not wrap in a warm\"\n",
        "wer8 = calculate_wer(reference_text8, hypothesis_text8)\n",
        "print(f\"Word Error Rate (WER): {wer8}\")"
      ],
      "metadata": {
        "id": "So1kD9T1Kms9",
        "outputId": "6dbb6150-f842-42c6-b429-e062e585b2c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.10/dist-packages (0.21.1)\n",
            "Requirement already satisfied: Levenshtein==0.21.1 in /usr/local/lib/python3.10/dist-packages (from python-Levenshtein) (0.21.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein==0.21.1->python-Levenshtein) (3.1.1)\n",
            "Word Error Rate (WER): 0.4\n",
            "Word Error Rate (WER): 0.4\n",
            "Word Error Rate (WER): 0.5\n",
            "Word Error Rate (WER): 0.6\n",
            "Word Error Rate (WER): 0.5\n",
            "Word Error Rate (WER): 0.2\n",
            "Word Error Rate (WER): 0.3\n",
            "Word Error Rate (WER): 0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üåµ  9. STT (subj1, rep1, last 4 words, original)**"
      ],
      "metadata": {
        "id": "mIwCsbE4aT6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#last 4 words (original)\n",
        "\n",
        "!pip install SpeechRecognition\n",
        "\n",
        "import os\n",
        "import speech_recognition as sr\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "\n",
        "    return text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"/content/sample_data/subj1_original_last4words\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")"
      ],
      "metadata": {
        "id": "xEMlSDv_jh87",
        "outputId": "4f1eacdd-a509-426b-9be5-3b8aadc9f58a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.10.0-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "Installing collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.10.0\n",
            "File: PYI_1_4_1_last4words.wav\n",
            "Text: in the warm clock\n",
            "Word Count: 4\n",
            "\n",
            "File: PYI_1_3_1_last4words.wav\n",
            "Text: in the alarm clock\n",
            "Word Count: 4\n",
            "\n",
            "File: PYI_1_8_1_last4words.wav\n",
            "Text: in the warm Club\n",
            "Word Count: 4\n",
            "\n",
            "File: PYI_1_7_1_last4words.wav\n",
            "Text: in the warm Club\n",
            "Word Count: 4\n",
            "\n",
            "File: PYI_1_5_1_last4words.wav\n",
            "Text: in a room\n",
            "Word Count: 3\n",
            "\n",
            "File: PYI_1_2_1_last4words.wav\n",
            "Text: enough alarm\n",
            "Word Count: 2\n",
            "\n",
            "File: PYI_1_6_1_last4words.wav\n",
            "Text: in a warm Club\n",
            "Word Count: 4\n",
            "\n",
            "File: PYI_1_1_1_last4words.wav\n",
            "Text: in alarm clock\n",
            "Word Count: 3\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üåµ 10. WER (subj1, rep1, last 4 words, original)**"
      ],
      "metadata": {
        "id": "MTOM2frKaaED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#subj1_sent_rep1_original_last4words\n",
        "\n",
        "!pip install python-Levenshtein\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return wer\n",
        "\n",
        "# Example usage\n",
        "reference_text1 = \"in a warm cloak\"\n",
        "hypothesis_text1 = \"in alarm clock\"\n",
        "wer1 = calculate_wer(reference_text1, hypothesis_text1)\n",
        "print(f\"Word Error Rate (WER): {wer1}\")\n",
        "\n",
        "reference_text2 = \"in a warm cloak\"\n",
        "hypothesis_text2 = \"enough alarm\"\n",
        "wer2 = calculate_wer(reference_text2, hypothesis_text2)\n",
        "print(f\"Word Error Rate (WER): {wer2}\")\n",
        "\n",
        "reference_text3 = \"in a warm cloak\"\n",
        "hypothesis_text3 = \"in the alarm clock\"\n",
        "wer3 = calculate_wer(reference_text3, hypothesis_text3)\n",
        "print(f\"Word Error Rate (WER): {wer3}\")\n",
        "\n",
        "reference_text4 = \"in a warm cloak\"\n",
        "hypothesis_text4 = \"in the warm clock\"\n",
        "wer4 = calculate_wer(reference_text4, hypothesis_text4)\n",
        "print(f\"Word Error Rate (WER): {wer4}\")\n",
        "\n",
        "reference_text5 = \"in a warm cloak\"\n",
        "hypothesis_text5 = \"in a room\"\n",
        "wer5 = calculate_wer(reference_text5, hypothesis_text5)\n",
        "print(f\"Word Error Rate (WER): {wer5}\")\n",
        "\n",
        "reference_text6 = \"in a warm cloak\"\n",
        "hypothesis_text6 = \"in a warm Club\"\n",
        "wer6 = calculate_wer(reference_text6, hypothesis_text6)\n",
        "print(f\"Word Error Rate (WER): {wer6}\")\n",
        "\n",
        "reference_text7 = \"in a warm cloak\"\n",
        "hypothesis_text7 = \"in the warm Club\"\n",
        "wer7 = calculate_wer(reference_text7, hypothesis_text7)\n",
        "print(f\"Word Error Rate (WER): {wer7}\")\n",
        "\n",
        "reference_text8 = \"in a warm cloak\"\n",
        "hypothesis_text8 = \"in the warm Club\"\n",
        "wer8 = calculate_wer(reference_text8, hypothesis_text8)\n",
        "print(f\"Word Error Rate (WER): {wer8}\")"
      ],
      "metadata": {
        "id": "ngwyegGUG17_",
        "outputId": "5c706ab3-25d8-43e6-8098-3e8644e0f080",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python_Levenshtein-0.21.1-py3-none-any.whl (9.4 kB)\n",
            "Collecting Levenshtein==0.21.1 (from python-Levenshtein)\n",
            "  Downloading Levenshtein-0.21.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=2.3.0 (from Levenshtein==0.21.1->python-Levenshtein)\n",
            "  Downloading rapidfuzz-3.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.21.1 python-Levenshtein-0.21.1 rapidfuzz-3.1.1\n",
            "Word Error Rate (WER): 0.75\n",
            "Word Error Rate (WER): 1.0\n",
            "Word Error Rate (WER): 0.75\n",
            "Word Error Rate (WER): 0.5\n",
            "Word Error Rate (WER): 0.5\n",
            "Word Error Rate (WER): 0.25\n",
            "Word Error Rate (WER): 0.5\n",
            "Word Error Rate (WER): 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**üêπ <font color = 'brown'> Noise cancellation and compression applied** ‚§µÔ∏è"
      ],
      "metadata": {
        "id": "20Agm7Dj7dJi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üêπ <font color = 'green'> google STT (SpeechRecognition package) applied to a list of compressed wav. files and their corresponding word count** ‚§µÔ∏è"
      ],
      "metadata": {
        "id": "bNexgs_58cLh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üêô **1. Transform original (rep1_sentence1) to denoised and compressed wav. format**"
      ],
      "metadata": {
        "id": "sruS4_UOUSKx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CQ6Nn8tycRf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# subj1_rep1_sentence1_original to denoised and comprsssed format\n",
        "\n",
        "!pip install librosa\n",
        "!pip install pydub\n",
        "!pip install numpy\n",
        "\n",
        "import os\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "\n",
        "from pydub import AudioSegment\n",
        "from pydub.effects import compress_dynamic_range\n",
        "\n",
        "def reduce_noise(audio_file, threshold=0.02):\n",
        "    y, sr = librosa.load(audio_file)\n",
        "\n",
        "    # Compute the short-term power of the audio\n",
        "    power = np.abs(librosa.stft(y))**2\n",
        "\n",
        "    # Set values below the threshold to zero\n",
        "    mask = power < threshold * np.max(power)\n",
        "    power[mask] = 0\n",
        "\n",
        "    # Reconstruct the audio\n",
        "    y_clean = librosa.istft(np.sqrt(power) * np.exp(1j * np.angle(librosa.stft(y))))\n",
        "\n",
        "    return y_clean, sr\n",
        "\n",
        "def compress_audio(audio_file, threshold=-20.0, ratio=4.0):\n",
        "    audio = AudioSegment.from_file(audio_file)\n",
        "\n",
        "    # Apply dynamic range compression\n",
        "    compressed_audio = compress_dynamic_range(audio, threshold=threshold, ratio=ratio)\n",
        "\n",
        "    return compressed_audio, audio.frame_rate\n",
        "\n",
        "# Path to the folder containing the sound files\n",
        "folder_path = \"/content/sample_data/subj1_sent_8original\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        # Apply noise reduction\n",
        "        denoised_audio, sr = reduce_noise(audio_file, threshold=0.02)\n",
        "\n",
        "        # Apply dynamic range compression\n",
        "        compressed_audio, sr = compress_audio(audio_file, threshold=-20.0, ratio=4.0)\n",
        "\n",
        "        # Save the denoised audio to a new file\n",
        "        denoised_filename = \"denoised_\" + filename\n",
        "        sf.write(denoised_filename, denoised_audio, sr)\n",
        "\n",
        "        # Save the compressed audio to a new file\n",
        "        compressed_filename = \"compressed_\" + filename\n",
        "        compressed_audio.export(compressed_filename, format=\"wav\")\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Denoised audio saved as: {denoised_filename}\")\n",
        "        print(f\"Compressed audio saved as: {compressed_filename}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVvvO0wJAofb",
        "outputId": "402f0601-37bc-4361-a554-22b701aa5a95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.0.post2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch<1.7,>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.5.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.2)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.5)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa) (23.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa) (2.27.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n",
            "File: PYI_1_4_1.wav\n",
            "Denoised audio saved as: denoised_PYI_1_4_1.wav\n",
            "Compressed audio saved as: compressed_PYI_1_4_1.wav\n",
            "\n",
            "File: PYI_1_8_1.wav\n",
            "Denoised audio saved as: denoised_PYI_1_8_1.wav\n",
            "Compressed audio saved as: compressed_PYI_1_8_1.wav\n",
            "\n",
            "File: PYI_1_1_1.wav\n",
            "Denoised audio saved as: denoised_PYI_1_1_1.wav\n",
            "Compressed audio saved as: compressed_PYI_1_1_1.wav\n",
            "\n",
            "File: PYI_1_7_1.wav\n",
            "Denoised audio saved as: denoised_PYI_1_7_1.wav\n",
            "Compressed audio saved as: compressed_PYI_1_7_1.wav\n",
            "\n",
            "File: PYI_1_3_1.wav\n",
            "Denoised audio saved as: denoised_PYI_1_3_1.wav\n",
            "Compressed audio saved as: compressed_PYI_1_3_1.wav\n",
            "\n",
            "File: PYI_1_5_1.wav\n",
            "Denoised audio saved as: denoised_PYI_1_5_1.wav\n",
            "Compressed audio saved as: compressed_PYI_1_5_1.wav\n",
            "\n",
            "File: PYI_1_2_1.wav\n",
            "Denoised audio saved as: denoised_PYI_1_2_1.wav\n",
            "Compressed audio saved as: compressed_PYI_1_2_1.wav\n",
            "\n",
            "File: PYI_1_6_1.wav\n",
            "Denoised audio saved as: denoised_PYI_1_6_1.wav\n",
            "Compressed audio saved as: compressed_PYI_1_6_1.wav\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üêô 2. STT (subj1, rep1, all text, compressed)**"
      ],
      "metadata": {
        "id": "kRaYMInjYMsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "\n",
        "import os\n",
        "import speech_recognition as sr\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "\n",
        "    return text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"/content/sample_data/subj1_para_8compressed\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvW9ttq68bWh",
        "outputId": "57b25549-8999-4bdb-a8a9-297e560a53b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "File: compressed_subj1_session1_rep4.wav\n",
            "Text: the nurse wind and the sun world is putting this was the stronger when a traveler came along with the warm clock they are read that the one who first succeeded in making the traveler take his clock off should be considered a stronger than the other than the north wind blow us hard as he could put the more he blew the more closely did The Traveler for his clock around him and unless the north wind gave up the tent in the song in the sky shine on me and immediately was alive to confess that the sun was the stronger of\n",
            "Word Count: 104\n",
            "\n",
            "File: compressed_subj1_session1_rep6.wav\n",
            "Text: the nurse mean and the song world is putting which was the stronger when a traveler came along rough in a warm clock they agreed that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could the more he blew the more closely together for his clock around him and I left the nursery was obviously to confess that the song was the stronger of the two\n",
            "Word Count: 87\n",
            "\n",
            "File: compressed_subj1_session1_rep8.wav\n",
            "Text: the nurse win and the sun was disputing which was the stronger when a traveler came along Route in the warm clothes they are great that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely the doctor for his clock around him and I left and there's one game of the attempt in the Sun in the sky shine at warmly and immediately to travel to the nurse when was over to confess that the sun was the stronger of the two\n",
            "Word Count: 111\n",
            "\n",
            "File: compressed_subj1_session1_rep1.wav\n",
            "Text: the nurse wind and the sun world is building which was the stronger when a traveler came along work in a warm clock they are reset the one who first succeeded in making the traveler take his clock of should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely The Traveler from his Club around him and I lost the nursery and immediately go traveling was only\n",
            "Word Count: 82\n",
            "\n",
            "File: compressed_subj1_session1_rep5.wav\n",
            "Text: the nurse win and the song where they speak English with the stronger when the traveler came or not in the room clock they agreed that the one who first succeed in making the traveler take his clock off should be considered stronger than the other than the north wind blew as hard as he could put the more he blew the more closely did the turbo for his Club around him and I left the list the nursery was over to confess that the song was the stronger of the two\n",
            "Word Count: 92\n",
            "\n",
            "File: compressed_subj1_session1_rep7.wav\n",
            "Text: the nurse win and the sun was disputing which was the stronger when a traveler came along Route in the warm clothes they are great that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely the doctor for his clock around him and I left and there's one game of the attempt in the Sun in the sky shine at warmly and immediately to travel to the nurse when was over to confess that the sun was the stronger of the two\n",
            "Word Count: 111\n",
            "\n",
            "File: compressed_subj1_session1_rep3.wav\n",
            "Text: the nurse win and the song world is putting which was Stronger when a traveler came around worked in the alarm clock they are really that the one who first succeed in making the traveler take his clothes off should be considered stronger than the other then the nurse wind blew as hard as he could but\n",
            "Word Count: 57\n",
            "\n",
            "File: compressed_subj1_session1_rep2.wav\n",
            "Text: the nursery and the sun world is putting which was Stronger when I travel I came along work in a warm Club they are really that the one who forced to succeed in making the traveler take his clock of should be considered stronger than the other in the nurse main blue as hard as he could put them away he blew the more closely did The Traveler for his Club around him and I lost the nursery nursery\n",
            "Word Count: 79\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üêô **3. WER (subj1, rep1, all text, compressed)**"
      ],
      "metadata": {
        "id": "XvldsYzJYg5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Temp\n",
        "\n",
        "!pip install python-Levenshtein\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return wer\n",
        "\n",
        "# Example usage\n",
        "reference_text1 = \"\"\n",
        "hypothesis_text1 = \"\"\n",
        "CFT_wer1 = calculate_wer(reference_text1, hypothesis_text1)\n",
        "print(f\"Word Error Rate (WER): {CFT_wer1}\")\n",
        "\n",
        "reference_text2 = \"\"\n",
        "hypothesis_text2 = \"\"\n",
        "CFT_wer2 = calculate_wer(reference_text2, hypothesis_text2)\n",
        "print(f\"Word Error Rate (WER): {CFT_wer2}\")\n",
        "\n",
        "reference_text3 = \"\"\n",
        "hypothesis_text3 = \"\"\n",
        "CFT_wer3 = calculate_wer(reference_text3, hypothesis_text3)\n",
        "print(f\"Word Error Rate (WER): {CFT_wer3}\")\n",
        "\n",
        "reference_text4 = \"\"\n",
        "hypothesis_text4 = \"\"\n",
        "CFT_wer4 = calculate_wer(reference_text4, hypothesis_text4)\n",
        "print(f\"Word Error Rate (WER): {CFT_wer4}\")\n",
        "\n",
        "reference_text5 = \"\"\n",
        "hypothesis_text5 = \"\"\n",
        "CFT_wer5 = calculate_wer(reference_text5, hypothesis_text5)\n",
        "print(f\"Word Error Rate (WER): {CFT_wer5}\")\n",
        "\n",
        "reference_text6 = \"\"\n",
        "hypothesis_text6 = \"\"\n",
        "CFT_wer6 = calculate_wer(reference_text6, hypothesis_text6)\n",
        "print(f\"Word Error Rate (WER): {CFT_wer6}\")\n",
        "\n",
        "reference_text7 = \"\"\n",
        "hypothesis_text7 = \"\"\n",
        "CFT_wer7 = calculate_wer(reference_text7, hypothesis_text7)\n",
        "print(f\"Word Error Rate (WER): {CFT_wer7}\")\n",
        "\n",
        "reference_text8 = \"\"\n",
        "hypothesis_text8 = \"\"\n",
        "CFT_wer8 = calculate_wer(reference_text8, hypothesis_text8)\n",
        "print(f\"Word Error Rate (WER): {CFT_wer8}\")"
      ],
      "metadata": {
        "id": "sCZR8Gwtz4S9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üêô **4. STT (subject1, rep1, sent1, compressed)**"
      ],
      "metadata": {
        "id": "S3dAP_qMU1ZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subject1_sentence1_compressed\n",
        "!pip install SpeechRecognition\n",
        "\n",
        "import os\n",
        "import speech_recognition as sr\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "\n",
        "    return text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"/content/sample_data/subj1_sent_8compressed\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0WCBGRGC7Gi",
        "outputId": "0bf7228b-892c-4b16-8549-fe2e4d0e107b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "File: compressed_PYI_1_1_1.wav\n",
            "Text: the nurse wind and the sun world is building which was the stronger when a traveler came along work in a warm clock\n",
            "Word Count: 23\n",
            "\n",
            "File: compressed_PYI_1_8_1.wav\n",
            "Text: The North Wind and the sun world is building which was the stronger when a traveler came or not in a warm\n",
            "Word Count: 22\n",
            "\n",
            "File: compressed_PYI_1_5_1.wav\n",
            "Text: the nurse win and the song where they speak English with the stronger when the traveler came or not in the wrong\n",
            "Word Count: 22\n",
            "\n",
            "File: compressed_PYI_1_4_1.wav\n",
            "Text: the nurse wind and the sun world is putting this was the stronger when a Traveller came out of work in the warm clock\n",
            "Word Count: 24\n",
            "\n",
            "File: compressed_PYI_1_3_1.wav\n",
            "Text: the nurse win and the song world is putting which was Stronger when a traveler came around worked in the alarm clock\n",
            "Word Count: 22\n",
            "\n",
            "File: compressed_PYI_1_6_1.wav\n",
            "Text: the nurse mean and the song world is putting which was the stronger when a traveler came along rough in a warm clock\n",
            "Word Count: 23\n",
            "\n",
            "File: compressed_PYI_1_2_1.wav\n",
            "Text: the nursery and the sun world is putting which was Stronger when I travel I came along work in a warm\n",
            "Word Count: 21\n",
            "\n",
            "File: compressed_PYI_1_7_1.wav\n",
            "Text: the nurse win and the sun was disputing which was the stronger when a traveler came along Route in the warm clothes\n",
            "Word Count: 22\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üêô **5. WER (subject1, rep1, sent1, compressed)**"
      ],
      "metadata": {
        "id": "L3nU8_fBVGxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#subj1_sent_rep1_sentence1_compressed\n",
        "\n",
        "!pip install python-Levenshtein\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return wer\n",
        "\n",
        "# Example usage\n",
        "reference_text1 = \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text1 = \"the nurse wind and the sun world is building which was the stronger when a traveler came along work in a warm clock\"\n",
        "wer1 = calculate_wer(reference_text1, hypothesis_text1)\n",
        "print(f\"Word Error Rate (WER): {wer1}\")\n",
        "\n",
        "reference_text2 = \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text2 = \"the nursery and the sun world is putting which was Stronger when I travel I came along work in a warm\"\n",
        "wer2 = calculate_wer(reference_text2, hypothesis_text2)\n",
        "print(f\"Word Error Rate (WER): {wer2}\")\n",
        "\n",
        "reference_text3 = \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text3 = \"the nurse win and the song world is putting which was Stronger when a traveler came around worked in the alarm clock\"\n",
        "wer3 = calculate_wer(reference_text3, hypothesis_text3)\n",
        "print(f\"Word Error Rate (WER): {wer3}\")\n",
        "\n",
        "reference_text4 = \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text4 = \"the nurse wind and the sun world is putting this was the stronger when a Traveller came out of work in the warm clock\"\n",
        "wer4 = calculate_wer(reference_text4, hypothesis_text4)\n",
        "print(f\"Word Error Rate (WER): {wer4}\")\n",
        "\n",
        "reference_text5 = \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text5 = \"the nurse win and the song where they speak English with the stronger when the traveler came or not in the wrong\"\n",
        "wer5 = calculate_wer(reference_text5, hypothesis_text5)\n",
        "print(f\"Word Error Rate (WER): {wer5}\")\n",
        "\n",
        "reference_text6 = \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text6 = \"the nurse mean and the song world is putting which was the stronger when a traveler came along rough in a warm clock\"\n",
        "wer6 = calculate_wer(reference_text6, hypothesis_text6)\n",
        "print(f\"Word Error Rate (WER): {wer6}\")\n",
        "\n",
        "reference_text7 = \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text7 = \"the nurse win and the sun was disputing which was the stronger when a traveler came along Route in the warm clothes\"\n",
        "wer7 = calculate_wer(reference_text7, hypothesis_text7)\n",
        "print(f\"Word Error Rate (WER): {wer7}\")\n",
        "\n",
        "reference_text8 = \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text8 = \"the North Wind and the sun world is building which was the stronger when a traveler came or not in a warm\"\n",
        "wer8 = calculate_wer(reference_text8, hypothesis_text8)\n",
        "print(f\"Word Error Rate (WER): {wer8}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MR36rYAiGlI5",
        "outputId": "d23ed2ce-d981-497f-9b05-178c29b694e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python_Levenshtein-0.21.1-py3-none-any.whl (9.4 kB)\n",
            "Collecting Levenshtein==0.21.1 (from python-Levenshtein)\n",
            "  Downloading Levenshtein-0.21.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=2.3.0 (from Levenshtein==0.21.1->python-Levenshtein)\n",
            "  Downloading rapidfuzz-3.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.21.1 python-Levenshtein-0.21.1 rapidfuzz-3.1.1\n",
            "Word Error Rate (WER): 0.2727272727272727\n",
            "Word Error Rate (WER): 0.5454545454545454\n",
            "Word Error Rate (WER): 0.5909090909090909\n",
            "Word Error Rate (WER): 0.5\n",
            "Word Error Rate (WER): 0.6363636363636364\n",
            "Word Error Rate (WER): 0.36363636363636365\n",
            "Word Error Rate (WER): 0.2727272727272727\n",
            "Word Error Rate (WER): 0.36363636363636365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üêô **6. STT (subject1, rep1, main clause, compressed)**\n",
        "###üê• **compressed sentence divided into main clause**"
      ],
      "metadata": {
        "id": "_7_fg4iOfNKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "\n",
        "import os\n",
        "import speech_recognition as sr\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "\n",
        "    return text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"/content/sample_data/subj1_compressed_main\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")"
      ],
      "metadata": {
        "id": "VJ5boQTRfP4p",
        "outputId": "c8d0d48d-b3a2-4909-d6f1-70eef35c9f44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "File: compressed_PYI_1_6_1_main.wav\n",
            "Text: the nurse mean and the song world is putting which was the stronger\n",
            "Word Count: 13\n",
            "\n",
            "File: compressed_PYI_1_7_1_main.wav\n",
            "Text: the nurse win and the sun was disputing which was the stronger\n",
            "Word Count: 12\n",
            "\n",
            "File: compressed_PYI_1_3_1_main.wav\n",
            "Text: the nurse win and the song world is putting which was Stronger\n",
            "Word Count: 12\n",
            "\n",
            "File: compressed_PYI_1_2_1_main.wav\n",
            "Text: the nursery and the sun world is putting which was Stronger\n",
            "Word Count: 11\n",
            "\n",
            "File: compressed_PYI_1_5_1_main.wav\n",
            "Text: the nurse wind and the sun world is building which was the stronger\n",
            "Word Count: 13\n",
            "\n",
            "File: compressed_PYI_1_8_1_main.wav\n",
            "Text: The North Wind and the sun world is building which was the stronger\n",
            "Word Count: 13\n",
            "\n",
            "File: compressed_PYI_1_4_1_main.wav\n",
            "Text: the nurse wind and the sun world is putting this was the stronger\n",
            "Word Count: 13\n",
            "\n",
            "File: compressed_PYI_1_1_1_main.wav\n",
            "Text: the nurse wind and the sun world is building which was the stronger\n",
            "Word Count: 13\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üêô **7. WER (subject1, rep1, main clause, compressed)**"
      ],
      "metadata": {
        "id": "YLYxi0CkVYMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#subj1_sent_rep1_compressed_main\n",
        "\n",
        "!pip install python-Levenshtein\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return wer\n",
        "\n",
        "# Example usage\n",
        "reference_text1 = \"the north wind and the sun were disputing which was the stronger\"\n",
        "hypothesis_text1 = \"the nurse wind and the sun world is building which was the stronger\"\n",
        "wer1 = calculate_wer(reference_text1, hypothesis_text1)\n",
        "print(f\"Word Error Rate (WER): {wer1}\")\n",
        "\n",
        "reference_text2 = \"the north wind and the sun were disputing which was the stronger\"\n",
        "hypothesis_text2 = \"the nursery and the sun world is putting which was Stronger\"\n",
        "wer2 = calculate_wer(reference_text2, hypothesis_text2)\n",
        "print(f\"Word Error Rate (WER): {wer2}\")\n",
        "\n",
        "reference_text3 = \"the north wind and the sun were disputing which was the stronger\"\n",
        "hypothesis_text3 = \"the nurse win and the song world is putting which was Stronger\"\n",
        "wer3 = calculate_wer(reference_text3, hypothesis_text3)\n",
        "print(f\"Word Error Rate (WER): {wer3}\")\n",
        "\n",
        "reference_text4 = \"the north wind and the sun were disputing which was the stronger\"\n",
        "hypothesis_text4 = \"the nurse wind and the sun world is putting this was the stronger\"\n",
        "wer4 = calculate_wer(reference_text4, hypothesis_text4)\n",
        "print(f\"Word Error Rate (WER): {wer4}\")\n",
        "\n",
        "reference_text5 = \"the north wind and the sun were disputing which was the stronger\"\n",
        "hypothesis_text5 = \"the nurse wind and the sun world is building which was the stronger\"\n",
        "wer5 = calculate_wer(reference_text5, hypothesis_text5)\n",
        "print(f\"Word Error Rate (WER): {wer5}\")\n",
        "\n",
        "reference_text6 = \"the north wind and the sun were disputing which was the stronger\"\n",
        "hypothesis_text6 = \"the nurse mean and the song world is putting which was the stronger\"\n",
        "wer6 = calculate_wer(reference_text6, hypothesis_text6)\n",
        "print(f\"Word Error Rate (WER): {wer6}\")\n",
        "\n",
        "reference_text7 = \"the north wind and the sun were disputing which was the stronger\"\n",
        "hypothesis_text7 = \"the nurse win and the sun was disputing which was the stronger\"\n",
        "wer7 = calculate_wer(reference_text7, hypothesis_text7)\n",
        "print(f\"Word Error Rate (WER): {wer7}\")\n",
        "\n",
        "reference_text8 = \"the north wind and the sun were disputing which was the stronger\"\n",
        "hypothesis_text8 = \"The North Wind and the sun world is building which was the stronger\"\n",
        "wer8 = calculate_wer(reference_text8, hypothesis_text8)\n",
        "print(f\"Word Error Rate (WER): {wer8}\")"
      ],
      "metadata": {
        "id": "NV60en-7KZTX",
        "outputId": "a72b5de9-a090-4358-8c59-bb8b4e14b893",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.10/dist-packages (0.21.1)\n",
            "Requirement already satisfied: Levenshtein==0.21.1 in /usr/local/lib/python3.10/dist-packages (from python-Levenshtein) (0.21.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein==0.21.1->python-Levenshtein) (3.1.1)\n",
            "Word Error Rate (WER): 0.3333333333333333\n",
            "Word Error Rate (WER): 0.5833333333333334\n",
            "Word Error Rate (WER): 0.6666666666666666\n",
            "Word Error Rate (WER): 0.4166666666666667\n",
            "Word Error Rate (WER): 0.3333333333333333\n",
            "Word Error Rate (WER): 0.5\n",
            "Word Error Rate (WER): 0.25\n",
            "Word Error Rate (WER): 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üêô **8. STT (subject1, rep1, subordinate clause, compressed)**\n",
        "###üê• **compressed sentence divided into subordinate clause**"
      ],
      "metadata": {
        "id": "uzhbakt0fPcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "\n",
        "import os\n",
        "import speech_recognition as sr\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "\n",
        "    return text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"/content/sample_data/subj1_compressed_subordinate\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")"
      ],
      "metadata": {
        "id": "PKaDfU0ifOPZ",
        "outputId": "90f672f3-8f86-4224-d598-708fee4f7731",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "File: compressed_PYI_1_2_1_subordinate.wav\n",
            "Text: bring a trailer came along work in a warm\n",
            "Word Count: 9\n",
            "\n",
            "File: compressed_PYI_1_3_1_subordinate.wav\n",
            "Text: when a traveler came around worked in the warm clock\n",
            "Word Count: 10\n",
            "\n",
            "File: compressed_PYI_1_5_1_subordinate.wav\n",
            "Text: when a traveler came or not in the room clock\n",
            "Word Count: 10\n",
            "\n",
            "File: compressed_PYI_1_1_1_subordinate.wav\n",
            "Text: Atlanta traveler came along work in a room clock\n",
            "Word Count: 9\n",
            "\n",
            "File: compressed_PYI_1_6_1_subordinate.wav\n",
            "Text: when a traveler came around in a warm clock\n",
            "Word Count: 9\n",
            "\n",
            "File: compressed_PYI_1_8_1_subordinate.wav\n",
            "Text: when a traveler came or not wrap in a warm\n",
            "Word Count: 10\n",
            "\n",
            "File: compressed_PYI_1_4_1_subordinate.wav\n",
            "Text: when a traveler came a little rough in the warm clock\n",
            "Word Count: 11\n",
            "\n",
            "File: compressed_PYI_1_7_1_subordinate.wav\n",
            "Text: when a traveler came along rough in the warm clothes\n",
            "Word Count: 10\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üêô **9. WER (subject1, rep1, subordinate clause, compressed)**"
      ],
      "metadata": {
        "id": "LdqCHcSjVpTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#subj1_sent_rep1_compressed_subordinate\n",
        "\n",
        "!pip install python-Levenshtein\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return wer\n",
        "\n",
        "# Example usage\n",
        "reference_text1 = \"when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text1 = \"Atlanta traveler came along work in a room clock\"\n",
        "wer1 = calculate_wer(reference_text1, hypothesis_text1)\n",
        "print(f\"Word Error Rate (WER): {wer1}\")\n",
        "\n",
        "reference_text2 = \"when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text2 = \"bring a trailer came along work in a warm\"\n",
        "wer2 = calculate_wer(reference_text2, hypothesis_text2)\n",
        "print(f\"Word Error Rate (WER): {wer2}\")\n",
        "\n",
        "reference_text3 = \"when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text3 = \"when a traveler came around worked in the warm clock\"\n",
        "wer3 = calculate_wer(reference_text3, hypothesis_text3)\n",
        "print(f\"Word Error Rate (WER): {wer3}\")\n",
        "\n",
        "reference_text4 = \"when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text4 = \"when a traveler came a little rough in the warm clock\"\n",
        "wer4 = calculate_wer(reference_text4, hypothesis_text4)\n",
        "print(f\"Word Error Rate (WER): {wer4}\")\n",
        "\n",
        "reference_text5 = \"when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text5 = \"when a traveler came or not in the room clock\"\n",
        "wer5 = calculate_wer(reference_text5, hypothesis_text5)\n",
        "print(f\"Word Error Rate (WER): {wer5}\")\n",
        "\n",
        "reference_text6 = \"when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text6 = \"when a traveler came around in a warm clock\"\n",
        "wer6 = calculate_wer(reference_text6, hypothesis_text6)\n",
        "print(f\"Word Error Rate (WER): {wer6}\")\n",
        "\n",
        "reference_text7 = \"when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text7 = \"when a traveler came along rough in the warm clothes\"\n",
        "wer7 = calculate_wer(reference_text7, hypothesis_text7)\n",
        "print(f\"Word Error Rate (WER): {wer7}\")\n",
        "\n",
        "reference_text8 = \"when a traveler came along wrapped in a warm cloak\"\n",
        "hypothesis_text8 = \"when a traveler came or not wrap in a warm\"\n",
        "wer8 = calculate_wer(reference_text8, hypothesis_text8)\n",
        "print(f\"Word Error Rate (WER): {wer8}\")"
      ],
      "metadata": {
        "id": "yRiiUoVNKVj9",
        "outputId": "985a1ffe-f196-4c4c-c1e5-a0aa60026b9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.10/dist-packages (0.21.1)\n",
            "Requirement already satisfied: Levenshtein==0.21.1 in /usr/local/lib/python3.10/dist-packages (from python-Levenshtein) (0.21.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein==0.21.1->python-Levenshtein) (3.1.1)\n",
            "Word Error Rate (WER): 0.5\n",
            "Word Error Rate (WER): 0.4\n",
            "Word Error Rate (WER): 0.4\n",
            "Word Error Rate (WER): 0.5\n",
            "Word Error Rate (WER): 0.5\n",
            "Word Error Rate (WER): 0.3\n",
            "Word Error Rate (WER): 0.3\n",
            "Word Error Rate (WER): 0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üêô **10. STT (subject1, rep1, last 4 words, compressed)**"
      ],
      "metadata": {
        "id": "AEwn4VHDWAGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#last 4 words (compressed)\n",
        "\n",
        "!pip install SpeechRecognition\n",
        "\n",
        "import os\n",
        "import speech_recognition as sr\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "\n",
        "    return text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"/content/sample_data/subj1_compressed_last4words\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")"
      ],
      "metadata": {
        "id": "ASE3Eyt6jaT0",
        "outputId": "0465b01c-eca7-4446-df44-d6aa924bec26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "File: compressed_PYI_1_1_1_last4words.wav\n",
            "Text: in alarm clock\n",
            "Word Count: 3\n",
            "\n",
            "File: compressed_PYI_1_3_1_last4words.wav\n",
            "Text: in the alarm clock\n",
            "Word Count: 4\n",
            "\n",
            "File: compressed_PYI_1_8_1_last4words.wav\n",
            "Text: in a war\n",
            "Word Count: 3\n",
            "\n",
            "File: compressed_PYI_1_7_1_last4words.wav\n",
            "Text: in the warm Club\n",
            "Word Count: 4\n",
            "\n",
            "File: compressed_PYI_1_5_1_last4words.wav\n",
            "Text: in a room\n",
            "Word Count: 3\n",
            "\n",
            "File: compressed_PYI_1_2_1_last4words.wav\n",
            "Text: enough alarm\n",
            "Word Count: 2\n",
            "\n",
            "File: compressed_PYI_1_4_1_last4words.wav\n",
            "Text: in the alarm clock\n",
            "Word Count: 4\n",
            "\n",
            "File: compressed_PYI_1_6_1_last4words.wav\n",
            "Text: in a warm Club\n",
            "Word Count: 4\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üêô **11. WER(subject1, rep1, last 4 words, compressed)**"
      ],
      "metadata": {
        "id": "NUU8aY4yWMlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#subj1_sent_rep1_compressed_last4words\n",
        "\n",
        "!pip install python-Levenshtein\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return wer\n",
        "\n",
        "# Example usage\n",
        "reference_text1 = \"in a warm cloak\"\n",
        "hypothesis_text1 = \"in alarm clock\"\n",
        "wer1 = calculate_wer(reference_text1, hypothesis_text1)\n",
        "print(f\"Word Error Rate (WER): {wer1}\")\n",
        "\n",
        "reference_text2 = \"in a warm cloak\"\n",
        "hypothesis_text2 = \"enough alarm\"\n",
        "wer2 = calculate_wer(reference_text2, hypothesis_text2)\n",
        "print(f\"Word Error Rate (WER): {wer2}\")\n",
        "\n",
        "reference_text3 = \"in a warm cloak\"\n",
        "hypothesis_text3 = \"in the alarm clock\"\n",
        "wer3 = calculate_wer(reference_text3, hypothesis_text3)\n",
        "print(f\"Word Error Rate (WER): {wer3}\")\n",
        "\n",
        "reference_text4 = \"in a warm cloak\"\n",
        "hypothesis_text4 = \"in the alarm clock\"\n",
        "wer4 = calculate_wer(reference_text4, hypothesis_text4)\n",
        "print(f\"Word Error Rate (WER): {wer4}\")\n",
        "\n",
        "reference_text5 = \"in a warm cloak\"\n",
        "hypothesis_text5 = \"in a room\"\n",
        "wer5 = calculate_wer(reference_text5, hypothesis_text5)\n",
        "print(f\"Word Error Rate (WER): {wer5}\")\n",
        "\n",
        "reference_text6 = \"in a warm cloak\"\n",
        "hypothesis_text6 = \"in a warm Club\"\n",
        "wer6 = calculate_wer(reference_text6, hypothesis_text6)\n",
        "print(f\"Word Error Rate (WER): {wer6}\")\n",
        "\n",
        "reference_text7 = \"in a warm cloak\"\n",
        "hypothesis_text7 = \"in the warm Club\"\n",
        "wer7 = calculate_wer(reference_text7, hypothesis_text7)\n",
        "print(f\"Word Error Rate (WER): {wer7}\")\n",
        "\n",
        "reference_text8 = \"in a warm cloak\"\n",
        "hypothesis_text8 = \"in a war\"\n",
        "wer8 = calculate_wer(reference_text8, hypothesis_text8)\n",
        "print(f\"Word Error Rate (WER): {wer8}\")"
      ],
      "metadata": {
        "id": "6aMIDjNUH_ZS",
        "outputId": "3a26be2c-a280-47ec-a348-706dbc800191",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.10/dist-packages (0.21.1)\n",
            "Requirement already satisfied: Levenshtein==0.21.1 in /usr/local/lib/python3.10/dist-packages (from python-Levenshtein) (0.21.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein==0.21.1->python-Levenshtein) (3.1.1)\n",
            "Word Error Rate (WER): 0.75\n",
            "Word Error Rate (WER): 1.0\n",
            "Word Error Rate (WER): 0.75\n",
            "Word Error Rate (WER): 0.75\n",
            "Word Error Rate (WER): 0.5\n",
            "Word Error Rate (WER): 0.25\n",
            "Word Error Rate (WER): 0.5\n",
            "Word Error Rate (WER): 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚ùé**Ignore below!**\n",
        "\n",
        "Word Error Rate\n",
        "\n",
        "Use small letters"
      ],
      "metadata": {
        "id": "GlUCzpTnGgsC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZU4a35-Gvns",
        "outputId": "472ad12d-8803-4e7a-af16-b5897ade0852"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the': 10, 'nurse': 2, 'wind': 2, 'and': 3, 'sun': 1, 'world': 1, 'is': 1, 'building': 1, 'which': 1, 'was': 2, 'stronger': 2, 'when': 1, 'a': 2, 'traveler': 2, 'came': 1, 'along': 1, 'work': 1, 'in': 2, 'warm': 1, 'clock': 2, 'they': 1, 'are': 1, 'reset': 1, 'one': 1, 'who': 1, 'first': 1, 'succeeded': 1, 'making': 1, 'take': 1, 'his': 2, 'of': 1, 'should': 1, 'be': 1, 'considered': 1, 'than': 2, 'other': 1, 'blew': 2, 'as': 2, 'hard': 1, 'he': 2, 'could': 1, 'but': 1, 'more': 2, 'closely': 1, 'The': 1, 'Traveler': 1, 'from': 1, 'Club': 1, 'around': 1, 'him': 1, 'I': 1, 'lost': 1, 'nursery': 1, 'immediately': 1, 'go': 1, 'traveling': 1, 'only': 1}\n"
          ]
        }
      ],
      "source": [
        "def word_count(text):\n",
        "    # Split the text into words\n",
        "    words = text.split()\n",
        "\n",
        "    # Create a dictionary to store word counts\n",
        "    word_counts = {}\n",
        "\n",
        "    # Count the occurrences of each word\n",
        "    for word in words:\n",
        "        if word in word_counts:\n",
        "            word_counts[word] += 1\n",
        "        else:\n",
        "            word_counts[word] = 1\n",
        "\n",
        "    return word_counts\n",
        "\n",
        "\n",
        "subj1_rep1_ori = \"the nurse wind and the sun world is building which was the stronger when a traveler came along work in a warm clock they are reset the one who first succeeded in making the traveler take his clock of should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely The Traveler from his Club around him and I lost the nursery and immediately go traveling was only\"\n",
        "counts = word_count(subj1_rep1_ori)\n",
        "print(counts)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "\n",
        "subj1_rep1_ori = \"the nurse wind and the sun world is building which was the stronger when a traveler came along work in a warm clock they are reset the one who first succeeded in making the traveler take his clock of should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely The Traveler from his Club around him and I lost the nursery and immediately go traveling was only\"\n",
        "wc1 = count_words(subj1_rep1_ori)\n",
        "print(wc1)\n",
        "\n",
        "subj1_rep1_compress = \"the nurse wind and the sun world is building which was the stronger when a traveler came along work in a warm clock they are reset the one who first succeeded in making the traveler take his clock of should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the\"\n",
        "wc1_1 = count_words(subj1_rep1_compress)\n",
        "print(wc1_1)\n",
        "print('\\n')\n",
        "\n",
        "subj1_rep2_ori = \"the nursery and the sun world is putting which was Stronger when I travel I came along work in a warm Club they are really that the one who forced to succeed in making the traveler take his clock of should be considered stronger than the other in the nurse main blue as hard as he could put them away he blew the more closely did The Traveler for his Club around him and I lost the nursery nursery\"\n",
        "wc2 = count_words(subj1_rep2_ori)\n",
        "print(wc2)\n",
        "\n",
        "subj1_rep2_compress = \"the nursery and the sun world is putting which was Stronger when I travel I came along work in a warm Club they are really that the one who forced to succeed in making the traveler take his clock of should be considered stronger than the other in the nurse main blue as hard as he could put them away he blew the more closely did The Traveler for his Club around him and I lost the nursery nursery\"\n",
        "wc2_1 = count_words(subj1_rep2_compress)\n",
        "print(wc2_1)\n",
        "print('\\n')\n",
        "\n",
        "subj1_rep3_ori = \"the nurse win and the song world is putting which was Stronger when a traveler came around worked in the alarm clock they are really that the one who first succeed in making the traveler take his clothes off should be considered stronger than the other then the nurse wind blew as hard as he could but\"\n",
        "wc3 = count_words(subj1_rep3_ori)\n",
        "print(wc3)\n",
        "\n",
        "subj1_rep3_compress = \"the nurse win and the song world is putting which was Stronger when a traveler came around worked in the alarm clock they are really that the one who first succeed in making the traveler take his clothes off should be considered stronger than the other then the nurse wind blew as hard as he could but\"\n",
        "wc3_1 = count_words(subj1_rep3_compress)\n",
        "print(wc3_1)\n",
        "print('\\n')\n",
        "\n",
        "subj1_rep4_ori = \"the nurse wind and the sun world is putting this was the stronger when a traveler came along with the warm clock they are read that the one who first succeeded in making the traveler take his clock off should be considered a stronger than the other than the north wind blow us hard as he could put the more he blew the more closely did The Traveler for his clock around him and unless the north wind gave up the tent in the song in the sky shine on me and immediately was alive to confess that the sun was the stronger of\"\n",
        "wc4 = count_words(subj1_rep4_ori)\n",
        "print(wc4)\n",
        "\n",
        "subj1_rep4_compress = \"the nurse wind and the sun world is putting this was the stronger when a traveler came out of work in the warm clock they are read that\"\n",
        "wc4_1 = count_words(subj1_rep4_compress)\n",
        "print(wc4_1)\n",
        "print('\\n')\n",
        "\n",
        "subj1_rep5_ori = \"the nurse win and the song where they speak English with the stronger when the traveler came or not in the room clock they agreed that the one who first succeed in making the traveler take his clock off should be considered stronger than the other than the north wind blew as hard as he could put the more\"\n",
        "wc5 = count_words(subj1_rep5_ori)\n",
        "print(wc5)\n",
        "\n",
        "subj1_rep5_compress = \"the nurse win and the song where they speak English with the stronger when the traveler came or not in the room clock they agreed that the one who first succeed in making the traveler take his clock off should be considered stronger than the other than the north wind blew as hard as he could put the more he blew the more closely did the turbo for his Club around him and I left the list the nursery\"\n",
        "wc5_1 = count_words(subj1_rep5_compress)\n",
        "print(wc5_1)\n",
        "print('\\n')\n",
        "\n",
        "subj1_rep6_ori = \"the nurse mean and the song world is putting which was the stronger when a traveler came along rough in a warm clock they agreed that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could the more he blew the more closely together for his clock around him and I left the nursery was obviously to confess that the song was the stronger of the two\"\n",
        "wc6 = count_words(subj1_rep6_ori)\n",
        "print(wc6)\n",
        "\n",
        "subj1_rep6_compress = \"the nurse mean and the song world is putting which was the stronger when a traveler came along rough in a warm clock they agreed that the one who first succeeded in\"\n",
        "wc6_1 = count_words(subj1_rep6_compress)\n",
        "print(wc6_1)\n",
        "print('\\n')\n",
        "\n",
        "subj1_rep7_ori = \"the nurse win and the sun was disputing which was the stronger when a traveler came along Route in the warm clothes they are great that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely the doctor for his clock around him and I left and there's one game of the attempt in the Sun in the sky shine at warmly and immediately to travel to the nurse when was over to confess that the sun was the stronger of the two\"\n",
        "wc7 = count_words(subj1_rep7_ori)\n",
        "print(wc7)\n",
        "\n",
        "subj1_rep7_compress = \"the nurse win and the sun was disputing which was the stronger when a traveler came along Route in the warm clothes they are great that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely the doctor for his clock around him and I left and there's one game of the attempt in the Sun in the sky shine at warmly and\"\n",
        "wc7_1 = count_words(subj1_rep7_compress)\n",
        "print(wc7_1)\n",
        "print('\\n')\n",
        "\n",
        "subj1_rep8_ori = \"the nurse win and the sun was disputing which was the stronger when a traveler came along Route in the warm clothes they are great that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely the doctor for his clock around him and I left and there's one game of the attempt in the Sun in the sky shine at warmly and immediately to travel to the nurse when was over to confess that the sun was the stronger of the two\"\n",
        "wc8 = count_words(subj1_rep8_ori)\n",
        "print(wc8)\n",
        "\n",
        "subj1_rep8_compress = \"the nurse win and the sun was disputing which was the stronger when a traveler came along Route in the warm clothes they are great that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the\"\n",
        "wc8_1 = count_words(subj1_rep8_compress)\n",
        "print(wc8_1)\n",
        "print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfxUl393Js2S",
        "outputId": "808c059b-0b1f-4bf5-ba16-dd684853a51e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "82\n",
            "62\n",
            "\n",
            "\n",
            "79\n",
            "79\n",
            "\n",
            "\n",
            "57\n",
            "57\n",
            "\n",
            "\n",
            "104\n",
            "28\n",
            "\n",
            "\n",
            "59\n",
            "79\n",
            "\n",
            "\n",
            "87\n",
            "32\n",
            "\n",
            "\n",
            "111\n",
            "91\n",
            "\n",
            "\n",
            "111\n",
            "62\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}